{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "Based on the paper titled \"Show and Tell: A Neural Image Caption Generator\" i choose to have an Encoder - Decoder Architecture, we start by Encoder which is a **pre-trained** CNN with a classification task, then we remove the last layer and we add a fully connected layer, wish is the features encoder, then we concatinate it to an Decoder, which a **non-trained** LSTM which result each time a one-hot vector with more than 8000 value, the value are mapped to a dictionary of words predefined already. than we apply a arg-sigmoid to get the predicted world each time. \n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    "I kept the parameters as they are:\n",
    "- The task is to describe a photo so i don't think we can downsample the image more than 256x256, if we do more we will lose details\n",
    "- i keept the image treatments as : RandomCrop, RandomHorizontalFlip, Normalize as they will be used as data augmentation and avoiding overfiting.\n",
    "- as batch size i putted 32, it is within the recommended range.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "i started by basic values as 256 for embeded size, 512 for hidden size and 32 as batch size and depends on the result of the model i will decide to keep or change them\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** i used Adam optimiser as it fix well the overfiting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
<<<<<<< HEAD
      "Done (t=0.63s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 779/414113 [00:00<00:58, 7047.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Done (t=0.89s)\n",
      "creating index...\n",
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 414113/414113 [00:44<00:00, 9292.94it/s]\n"
=======
      "\n",
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 329/414113 [00:00<02:05, 3284.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 776/414113 [00:00<01:55, 3567.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1235/414113 [00:00<01:48, 3820.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1689/414113 [00:00<01:42, 4010.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2142/414113 [00:00<01:39, 4151.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2594/414113 [00:00<01:36, 4253.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3041/414113 [00:00<01:35, 4313.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3481/414113 [00:00<01:34, 4338.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3939/414113 [00:00<01:33, 4406.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4399/414113 [00:01<01:31, 4460.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4853/414113 [00:01<01:31, 4483.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5317/414113 [00:01<01:30, 4527.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5775/414113 [00:01<01:29, 4540.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6231/414113 [00:01<01:29, 4543.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6695/414113 [00:01<01:29, 4569.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7151/414113 [00:01<01:29, 4542.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7608/414113 [00:01<01:29, 4548.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8063/414113 [00:01<01:29, 4548.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8523/414113 [00:01<01:28, 4562.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8985/414113 [00:02<01:28, 4577.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9443/414113 [00:02<01:28, 4566.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9902/414113 [00:02<01:28, 4572.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10360/414113 [00:02<01:28, 4563.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10817/414113 [00:02<01:28, 4555.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11273/414113 [00:02<01:28, 4548.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11728/414113 [00:02<01:28, 4523.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12189/414113 [00:02<01:28, 4546.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12644/414113 [00:02<01:28, 4522.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13108/414113 [00:02<01:27, 4556.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13564/414113 [00:03<01:28, 4531.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14033/414113 [00:03<01:27, 4577.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14494/414113 [00:03<01:27, 4586.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14955/414113 [00:03<01:26, 4591.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 15424/414113 [00:03<01:26, 4620.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 15887/414113 [00:03<01:26, 4623.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16350/414113 [00:03<01:26, 4584.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16814/414113 [00:03<01:26, 4598.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17274/414113 [00:03<01:28, 4466.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17738/414113 [00:03<01:27, 4515.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18198/414113 [00:04<01:27, 4539.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 18653/414113 [00:04<01:27, 4530.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19108/414113 [00:04<01:27, 4533.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19575/414113 [00:04<01:26, 4572.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20033/414113 [00:04<01:26, 4562.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20490/414113 [00:04<01:27, 4520.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 20943/414113 [00:04<01:27, 4509.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21408/414113 [00:04<01:26, 4549.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21864/414113 [00:04<01:26, 4535.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22336/414113 [00:04<01:25, 4586.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 22803/414113 [00:05<01:24, 4611.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23265/414113 [00:05<01:25, 4592.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23725/414113 [00:05<01:25, 4570.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24185/414113 [00:05<01:25, 4577.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24643/414113 [00:05<01:25, 4550.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25102/414113 [00:05<01:25, 4562.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25567/414113 [00:05<01:24, 4587.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26026/414113 [00:05<01:25, 4516.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26486/414113 [00:05<01:25, 4539.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 26951/414113 [00:05<01:24, 4570.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27409/414113 [00:06<01:25, 4542.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27875/414113 [00:06<01:24, 4576.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28337/414113 [00:06<01:24, 4588.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28804/414113 [00:06<01:23, 4611.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29266/414113 [00:06<01:23, 4608.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29727/414113 [00:06<01:23, 4598.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30188/414113 [00:06<01:23, 4599.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30655/414113 [00:06<01:23, 4615.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31129/414113 [00:06<01:22, 4649.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31595/414113 [00:06<01:22, 4652.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32061/414113 [00:07<01:22, 4643.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32526/414113 [00:07<01:22, 4641.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32991/414113 [00:07<01:23, 4560.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33455/414113 [00:07<01:23, 4581.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33914/414113 [00:07<01:22, 4583.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34378/414113 [00:07<01:22, 4599.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34839/414113 [00:07<01:23, 4554.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35295/414113 [00:07<01:23, 4533.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35749/414113 [00:07<01:23, 4516.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 36205/414113 [00:07<01:23, 4528.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36664/414113 [00:08<01:23, 4544.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37119/414113 [00:08<01:23, 4534.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37578/414113 [00:08<01:22, 4547.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38036/414113 [00:08<01:22, 4555.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38492/414113 [00:08<01:22, 4552.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38948/414113 [00:08<01:22, 4535.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39408/414113 [00:08<01:22, 4553.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39876/414113 [00:08<01:21, 4587.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40341/414113 [00:08<01:21, 4604.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40808/414113 [00:08<01:20, 4623.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 41271/414113 [00:09<01:20, 4607.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 41733/414113 [00:09<01:20, 4609.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42194/414113 [00:09<01:20, 4591.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42654/414113 [00:09<01:21, 4575.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 43116/414113 [00:09<01:20, 4588.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 43575/414113 [00:09<01:20, 4575.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44033/414113 [00:09<01:21, 4556.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44489/414113 [00:09<01:21, 4545.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44944/414113 [00:09<01:21, 4545.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45399/414113 [00:09<01:21, 4537.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45853/414113 [00:10<01:21, 4518.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 46305/414113 [00:10<01:23, 4415.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 46767/414113 [00:10<01:22, 4471.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 47234/414113 [00:10<01:21, 4529.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 47696/414113 [00:10<01:20, 4553.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48165/414113 [00:10<01:19, 4592.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48625/414113 [00:10<01:19, 4585.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49084/414113 [00:10<01:20, 4515.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49539/414113 [00:10<01:20, 4524.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49997/414113 [00:10<01:20, 4541.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50469/414113 [00:11<01:19, 4591.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50936/414113 [00:11<01:18, 4613.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 51401/414113 [00:11<01:18, 4623.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 51864/414113 [00:11<01:18, 4616.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52331/414113 [00:11<01:18, 4630.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52797/414113 [00:11<01:17, 4638.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53261/414113 [00:11<01:18, 4620.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53724/414113 [00:11<01:18, 4564.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54190/414113 [00:11<01:18, 4592.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54651/414113 [00:11<01:18, 4596.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 55113/414113 [00:12<01:18, 4600.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 55580/414113 [00:12<01:17, 4618.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 56054/414113 [00:12<01:16, 4652.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 56520/414113 [00:12<01:16, 4645.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 56985/414113 [00:12<01:16, 4646.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57450/414113 [00:12<01:17, 4622.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57913/414113 [00:12<01:17, 4574.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58372/414113 [00:12<01:17, 4577.58it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 58830/414113 [00:13<02:17, 2582.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59291/414113 [00:13<01:59, 2973.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59750/414113 [00:13<01:46, 3324.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60211/414113 [00:13<01:37, 3627.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60673/414113 [00:13<01:31, 3875.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61110/414113 [00:13<01:28, 4010.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61568/414113 [00:13<01:24, 4164.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 62028/414113 [00:13<01:22, 4284.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62481/414113 [00:13<01:20, 4352.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62944/414113 [00:14<01:19, 4430.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63404/414113 [00:14<01:18, 4477.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63866/414113 [00:14<01:17, 4517.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 64323/414113 [00:14<01:17, 4530.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 64780/414113 [00:14<01:17, 4527.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 65241/414113 [00:14<01:16, 4550.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 65700/414113 [00:14<01:16, 4561.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66164/414113 [00:14<01:15, 4582.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66626/414113 [00:14<01:15, 4591.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 67086/414113 [00:14<01:15, 4578.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 67545/414113 [00:15<01:15, 4563.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 68009/414113 [00:15<01:15, 4584.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 68468/414113 [00:15<01:15, 4574.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 68927/414113 [00:15<01:15, 4578.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69394/414113 [00:15<01:14, 4602.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69855/414113 [00:15<01:15, 4541.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70317/414113 [00:15<01:15, 4562.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70774/414113 [00:15<01:15, 4546.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71229/414113 [00:15<01:15, 4540.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71684/414113 [00:15<01:15, 4538.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 72138/414113 [00:16<01:15, 4508.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 72597/414113 [00:16<01:15, 4532.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73065/414113 [00:16<01:14, 4575.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73535/414113 [00:16<01:13, 4612.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74001/414113 [00:16<01:13, 4625.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74464/414113 [00:16<01:13, 4593.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74924/414113 [00:16<01:14, 4572.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75382/414113 [00:16<01:14, 4524.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75841/414113 [00:16<01:14, 4541.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 76306/414113 [00:16<01:13, 4573.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 76773/414113 [00:17<01:13, 4599.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 77234/414113 [00:17<01:14, 4498.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 77703/414113 [00:17<01:13, 4554.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78169/414113 [00:17<01:13, 4584.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78629/414113 [00:17<01:13, 4587.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79095/414113 [00:17<01:12, 4607.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79556/414113 [00:17<01:12, 4583.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 80015/414113 [00:17<01:13, 4574.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 80477/414113 [00:17<01:12, 4587.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 80936/414113 [00:18<01:12, 4571.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81407/414113 [00:18<01:12, 4611.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81869/414113 [00:18<01:12, 4580.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 82335/414113 [00:18<01:12, 4602.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 82803/414113 [00:18<01:11, 4622.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83273/414113 [00:18<01:11, 4643.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83738/414113 [00:18<01:11, 4607.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84206/414113 [00:18<01:11, 4628.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84669/414113 [00:18<01:11, 4626.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85138/414113 [00:18<01:10, 4642.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85603/414113 [00:19<01:10, 4629.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86070/414113 [00:19<01:10, 4639.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86538/414113 [00:19<01:10, 4648.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87005/414113 [00:19<01:10, 4653.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87471/414113 [00:19<01:10, 4649.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87936/414113 [00:19<01:10, 4640.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88401/414113 [00:19<01:10, 4640.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88866/414113 [00:19<01:10, 4633.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89330/414113 [00:19<01:10, 4625.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89793/414113 [00:19<01:10, 4612.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90255/414113 [00:20<01:10, 4612.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90721/414113 [00:20<01:09, 4625.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91184/414113 [00:20<01:09, 4625.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91647/414113 [00:20<01:09, 4622.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92110/414113 [00:20<01:10, 4595.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92574/414113 [00:20<01:09, 4608.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 93040/414113 [00:20<01:09, 4622.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 93503/414113 [00:20<01:09, 4624.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 93966/414113 [00:20<01:09, 4625.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94431/414113 [00:20<01:09, 4629.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94895/414113 [00:21<01:08, 4631.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95366/414113 [00:21<01:08, 4653.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95836/414113 [00:21<01:08, 4664.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96303/414113 [00:21<01:08, 4658.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96769/414113 [00:21<01:09, 4564.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 97239/414113 [00:21<01:08, 4603.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 97705/414113 [00:21<01:08, 4620.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 98171/414113 [00:21<01:08, 4631.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 98635/414113 [00:21<01:08, 4600.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99097/414113 [00:21<01:08, 4605.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99558/414113 [00:22<01:08, 4601.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100025/414113 [00:22<01:07, 4621.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100488/414113 [00:22<01:08, 4603.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100952/414113 [00:22<01:07, 4612.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 101414/414113 [00:22<01:08, 4573.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 101872/414113 [00:22<01:08, 4572.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102333/414113 [00:22<01:08, 4582.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102801/414113 [00:22<01:07, 4608.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 103265/414113 [00:22<01:07, 4617.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 103727/414113 [00:22<01:07, 4595.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104195/414113 [00:23<01:07, 4619.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104658/414113 [00:23<01:07, 4612.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 105120/414113 [00:23<01:07, 4588.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 105579/414113 [00:23<01:07, 4585.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106046/414113 [00:23<01:06, 4610.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106508/414113 [00:23<01:06, 4603.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106969/414113 [00:23<01:06, 4604.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107430/414113 [00:23<01:06, 4594.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107890/414113 [00:23<01:06, 4584.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 108349/414113 [00:23<01:07, 4497.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 108802/414113 [00:24<01:07, 4506.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109258/414113 [00:24<01:07, 4521.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109723/414113 [00:24<01:06, 4555.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110187/414113 [00:24<01:06, 4578.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110653/414113 [00:24<01:05, 4602.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111114/414113 [00:24<01:05, 4598.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111578/414113 [00:24<01:05, 4609.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112049/414113 [00:24<01:05, 4637.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112513/414113 [00:24<01:05, 4620.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112976/414113 [00:24<01:05, 4617.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 113443/414113 [00:25<01:04, 4630.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 113907/414113 [00:25<01:04, 4620.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114370/414113 [00:25<01:04, 4611.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114842/414113 [00:25<01:04, 4642.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115307/414113 [00:25<01:04, 4644.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115772/414113 [00:25<01:04, 4640.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116237/414113 [00:25<01:04, 4623.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116700/414113 [00:25<01:04, 4582.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 117159/414113 [00:25<01:05, 4535.44it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 117627/414113 [00:25<01:04, 4574.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118098/414113 [00:26<01:04, 4614.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118560/414113 [00:26<01:04, 4607.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 119026/414113 [00:26<01:03, 4623.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119496/414113 [00:26<01:03, 4644.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119961/414113 [00:26<01:03, 4617.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120423/414113 [00:26<01:04, 4545.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120878/414113 [00:26<01:04, 4542.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121344/414113 [00:26<01:03, 4575.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121802/414113 [00:26<01:03, 4575.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122266/414113 [00:26<01:03, 4594.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122726/414113 [00:27<01:03, 4572.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123184/414113 [00:27<01:03, 4547.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123641/414113 [00:27<01:03, 4553.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 124116/414113 [00:27<01:02, 4609.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 124588/414113 [00:27<01:02, 4640.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125066/414113 [00:27<01:01, 4680.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125535/414113 [00:27<01:02, 4607.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 126002/414113 [00:27<01:02, 4625.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 126472/414113 [00:27<01:01, 4646.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 126950/414113 [00:27<01:01, 4683.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127422/414113 [00:28<01:01, 4691.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127892/414113 [00:28<01:01, 4671.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128368/414113 [00:28<01:00, 4696.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128838/414113 [00:28<01:00, 4682.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 129307/414113 [00:28<01:01, 4642.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 129776/414113 [00:28<01:01, 4656.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 130242/414113 [00:28<01:01, 4640.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 130714/414113 [00:28<01:00, 4663.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131181/414113 [00:28<01:00, 4662.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131649/414113 [00:28<01:00, 4666.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132116/414113 [00:29<01:00, 4633.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132581/414113 [00:29<01:00, 4638.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133045/414113 [00:29<01:00, 4632.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133509/414113 [00:29<01:01, 4594.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133969/414113 [00:29<01:00, 4594.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 134429/414113 [00:29<01:01, 4564.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 134886/414113 [00:29<01:01, 4513.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135346/414113 [00:29<01:01, 4538.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135811/414113 [00:29<01:00, 4569.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136276/414113 [00:29<01:00, 4592.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136736/414113 [00:30<01:00, 4579.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137205/414113 [00:30<01:00, 4611.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137669/414113 [00:30<00:59, 4617.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 138136/414113 [00:30<00:59, 4630.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 138607/414113 [00:30<00:59, 4651.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 139073/414113 [00:30<00:59, 4605.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 139534/414113 [00:30<00:59, 4596.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 139998/414113 [00:30<00:59, 4607.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140459/414113 [00:30<00:59, 4608.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140922/414113 [00:31<00:59, 4614.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141385/414113 [00:31<00:59, 4615.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141847/414113 [00:31<00:59, 4587.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 142315/414113 [00:31<00:58, 4614.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 142778/414113 [00:31<00:58, 4618.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143247/414113 [00:31<00:58, 4636.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143714/414113 [00:31<00:58, 4644.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144179/414113 [00:31<00:58, 4631.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144643/414113 [00:31<00:58, 4632.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145109/414113 [00:31<00:57, 4638.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145579/414113 [00:32<00:57, 4655.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146047/414113 [00:32<00:57, 4660.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146514/414113 [00:32<00:57, 4633.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146985/414113 [00:32<00:57, 4654.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147451/414113 [00:32<00:58, 4568.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147914/414113 [00:32<00:58, 4585.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148379/414113 [00:32<00:57, 4604.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148843/414113 [00:32<00:57, 4613.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149316/414113 [00:32<00:56, 4647.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149783/414113 [00:32<00:56, 4652.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 150249/414113 [00:33<00:57, 4608.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 150722/414113 [00:33<00:56, 4643.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151192/414113 [00:33<00:56, 4658.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151660/414113 [00:33<00:56, 4664.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152127/414113 [00:33<00:56, 4664.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152595/414113 [00:33<00:56, 4668.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153068/414113 [00:33<00:55, 4684.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153542/414113 [00:33<00:55, 4698.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154018/414113 [00:33<00:55, 4714.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154490/414113 [00:33<00:55, 4699.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154960/414113 [00:34<00:55, 4681.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155429/414113 [00:34<00:55, 4666.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155896/414113 [00:34<00:55, 4645.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156363/414113 [00:34<00:55, 4652.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156830/414113 [00:34<00:55, 4656.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157296/414113 [00:34<00:55, 4642.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157761/414113 [00:34<00:55, 4642.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158226/414113 [00:34<00:55, 4644.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158691/414113 [00:34<00:55, 4632.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 159160/414113 [00:34<00:54, 4646.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 159634/414113 [00:35<00:54, 4672.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 160110/414113 [00:35<00:54, 4697.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 160580/414113 [00:35<00:55, 4535.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161057/414113 [00:35<00:54, 4601.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161526/414113 [00:35<00:54, 4623.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161998/414113 [00:35<00:54, 4651.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162472/414113 [00:35<00:53, 4676.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162941/414113 [00:35<00:53, 4672.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 163414/414113 [00:35<00:53, 4687.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 163884/414113 [00:35<00:53, 4676.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164352/414113 [00:36<00:53, 4655.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164818/414113 [00:36<00:53, 4622.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 165281/414113 [00:36<00:53, 4622.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 165744/414113 [00:36<00:54, 4587.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166203/414113 [00:36<00:54, 4568.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166660/414113 [00:36<00:54, 4551.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 167116/414113 [00:36<00:54, 4536.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 167579/414113 [00:36<00:54, 4562.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168043/414113 [00:36<00:53, 4584.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168509/414113 [00:36<00:53, 4604.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168970/414113 [00:37<00:53, 4602.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169431/414113 [00:37<00:53, 4599.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169891/414113 [00:37<00:53, 4583.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 170359/414113 [00:37<00:52, 4610.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 170823/414113 [00:37<00:52, 4616.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171285/414113 [00:37<00:52, 4586.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171744/414113 [00:37<00:53, 4551.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172200/414113 [00:37<00:53, 4551.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172656/414113 [00:37<00:54, 4408.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173115/414113 [00:37<00:54, 4461.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173567/414113 [00:38<00:53, 4478.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174017/414113 [00:38<00:53, 4484.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174477/414113 [00:38<00:53, 4517.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174938/414113 [00:38<00:52, 4542.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175393/414113 [00:38<00:52, 4527.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175846/414113 [00:38<01:50, 2159.47it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 176297/414113 [00:39<01:32, 2559.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176765/414113 [00:39<01:20, 2961.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177234/414113 [00:39<01:11, 3328.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177702/414113 [00:39<01:04, 3643.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178162/414113 [00:39<01:00, 3883.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178625/414113 [00:39<00:57, 4079.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179090/414113 [00:39<00:55, 4234.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179556/414113 [00:39<00:53, 4351.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 180016/414113 [00:39<00:52, 4422.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180474/414113 [00:39<00:52, 4454.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180931/414113 [00:40<00:51, 4487.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 181397/414113 [00:40<00:51, 4537.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 181857/414113 [00:40<00:51, 4477.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182325/414113 [00:40<00:51, 4534.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182782/414113 [00:40<00:50, 4541.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183246/414113 [00:40<00:50, 4567.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183705/414113 [00:40<00:50, 4561.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 184163/414113 [00:40<00:50, 4527.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 184617/414113 [00:40<00:50, 4530.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185082/414113 [00:40<00:50, 4564.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185553/414113 [00:41<00:49, 4604.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 186015/414113 [00:41<00:49, 4608.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 186478/414113 [00:41<00:49, 4614.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 186949/414113 [00:41<00:48, 4641.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187414/414113 [00:41<00:49, 4583.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187873/414113 [00:41<00:49, 4577.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 188331/414113 [00:41<00:49, 4518.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 188784/414113 [00:41<00:50, 4504.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189242/414113 [00:41<00:49, 4524.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189695/414113 [00:41<00:49, 4508.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190146/414113 [00:42<00:49, 4508.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190614/414113 [00:42<00:49, 4558.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 191084/414113 [00:42<00:48, 4598.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 191557/414113 [00:42<00:48, 4635.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192021/414113 [00:42<00:48, 4615.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192483/414113 [00:42<00:48, 4569.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 192941/414113 [00:42<00:49, 4502.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193392/414113 [00:42<00:49, 4456.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193839/414113 [00:42<00:49, 4459.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194286/414113 [00:42<00:49, 4410.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194733/414113 [00:43<00:49, 4427.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195189/414113 [00:43<00:49, 4465.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195643/414113 [00:43<00:48, 4484.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 196101/414113 [00:43<00:48, 4510.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 196553/414113 [00:43<00:48, 4488.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197002/414113 [00:43<00:48, 4481.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197451/414113 [00:43<00:48, 4471.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197904/414113 [00:43<00:48, 4486.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198353/414113 [00:43<00:48, 4484.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198807/414113 [00:43<00:47, 4500.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199271/414113 [00:44<00:47, 4539.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199726/414113 [00:44<00:47, 4532.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200180/414113 [00:44<00:47, 4516.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200641/414113 [00:44<00:46, 4543.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201096/414113 [00:44<00:46, 4532.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201566/414113 [00:44<00:46, 4581.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202025/414113 [00:44<00:46, 4581.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202485/414113 [00:44<00:46, 4585.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202949/414113 [00:44<00:45, 4599.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203417/414113 [00:44<00:45, 4621.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203880/414113 [00:45<00:45, 4608.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204341/414113 [00:45<00:46, 4465.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204809/414113 [00:45<00:46, 4526.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205272/414113 [00:45<00:45, 4555.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205729/414113 [00:45<00:45, 4546.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206185/414113 [00:45<00:45, 4532.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206640/414113 [00:45<00:45, 4537.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207101/414113 [00:45<00:45, 4558.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207567/414113 [00:45<00:45, 4585.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208030/414113 [00:46<00:44, 4598.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208490/414113 [00:46<00:44, 4594.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208958/414113 [00:46<00:44, 4616.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209420/414113 [00:46<00:44, 4590.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209883/414113 [00:46<00:44, 4600.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210344/414113 [00:46<00:44, 4556.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210811/414113 [00:46<00:44, 4589.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211276/414113 [00:46<00:44, 4605.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211743/414113 [00:46<00:43, 4623.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 212206/414113 [00:46<00:43, 4607.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 212667/414113 [00:47<00:43, 4598.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 213128/414113 [00:47<00:43, 4600.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 213589/414113 [00:47<00:43, 4601.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214055/414113 [00:47<00:43, 4615.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214519/414113 [00:47<00:43, 4621.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214983/414113 [00:47<00:43, 4626.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215446/414113 [00:47<00:43, 4615.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215908/414113 [00:47<00:43, 4572.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216374/414113 [00:47<00:43, 4596.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216838/414113 [00:47<00:42, 4609.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 217306/414113 [00:48<00:42, 4629.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 217776/414113 [00:48<00:42, 4648.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218241/414113 [00:48<00:42, 4634.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218726/414113 [00:48<00:41, 4694.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219196/414113 [00:48<00:42, 4599.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219671/414113 [00:48<00:41, 4642.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220136/414113 [00:48<00:41, 4624.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220599/414113 [00:48<00:42, 4595.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 221059/414113 [00:48<00:43, 4463.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 221524/414113 [00:48<00:42, 4516.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 221994/414113 [00:49<00:42, 4568.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 222471/414113 [00:49<00:41, 4626.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 222938/414113 [00:49<00:41, 4638.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223412/414113 [00:49<00:40, 4666.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223880/414113 [00:49<00:41, 4638.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224348/414113 [00:49<00:40, 4649.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224814/414113 [00:49<00:40, 4630.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 225278/414113 [00:49<00:40, 4626.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 225741/414113 [00:49<00:40, 4599.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226209/414113 [00:49<00:40, 4621.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226687/414113 [00:50<00:40, 4667.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 227155/414113 [00:50<00:40, 4670.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 227636/414113 [00:50<00:39, 4710.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228113/414113 [00:50<00:39, 4726.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228586/414113 [00:50<00:39, 4720.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229059/414113 [00:50<00:39, 4673.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229527/414113 [00:50<00:39, 4624.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 229990/414113 [00:50<00:40, 4584.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230450/414113 [00:50<00:40, 4587.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230909/414113 [00:50<00:39, 4580.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231368/414113 [00:51<00:40, 4542.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231826/414113 [00:51<00:40, 4552.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232282/414113 [00:51<00:40, 4528.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232735/414113 [00:51<00:40, 4481.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233196/414113 [00:51<00:40, 4518.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233649/414113 [00:51<00:39, 4521.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 234102/414113 [00:51<00:39, 4505.02it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 234565/414113 [00:51<00:39, 4540.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235020/414113 [00:51<00:39, 4543.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235475/414113 [00:51<00:39, 4510.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235927/414113 [00:52<00:39, 4496.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236380/414113 [00:52<00:39, 4504.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236833/414113 [00:52<00:39, 4511.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237295/414113 [00:52<00:38, 4543.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237753/414113 [00:52<00:38, 4552.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238213/414113 [00:52<00:38, 4566.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238670/414113 [00:52<00:38, 4542.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239125/414113 [00:52<00:38, 4531.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239582/414113 [00:52<00:38, 4541.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240039/414113 [00:52<00:38, 4548.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240496/414113 [00:53<00:38, 4552.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240961/414113 [00:53<00:37, 4579.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241421/414113 [00:53<00:37, 4585.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241880/414113 [00:53<00:37, 4534.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 242334/414113 [00:53<00:38, 4518.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 242792/414113 [00:53<00:37, 4534.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 243255/414113 [00:53<00:37, 4560.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 243714/414113 [00:53<00:37, 4567.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244171/414113 [00:53<00:37, 4558.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244627/414113 [00:53<00:37, 4539.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245081/414113 [00:54<00:37, 4533.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245541/414113 [00:54<00:37, 4551.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245997/414113 [00:54<00:37, 4523.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 246460/414113 [00:54<00:36, 4554.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 246916/414113 [00:54<00:36, 4549.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247372/414113 [00:54<00:36, 4510.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247826/414113 [00:54<00:36, 4518.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 248281/414113 [00:54<00:36, 4525.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 248734/414113 [00:54<00:36, 4492.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249186/414113 [00:54<00:36, 4499.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249637/414113 [00:55<00:36, 4461.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 250100/414113 [00:55<00:36, 4509.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 250552/414113 [00:55<00:36, 4492.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251002/414113 [00:55<00:36, 4477.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251461/414113 [00:55<00:36, 4508.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251920/414113 [00:55<00:35, 4530.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252374/414113 [00:55<00:36, 4483.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252823/414113 [00:55<00:36, 4472.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 253274/414113 [00:55<00:35, 4482.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 253723/414113 [00:56<00:35, 4473.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 254180/414113 [00:56<00:35, 4501.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 254631/414113 [00:56<00:35, 4496.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255094/414113 [00:56<00:35, 4534.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255548/414113 [00:56<00:35, 4511.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256010/414113 [00:56<00:34, 4541.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256465/414113 [00:56<00:34, 4518.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256917/414113 [00:56<00:34, 4501.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257370/414113 [00:56<00:34, 4508.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257826/414113 [00:56<00:34, 4523.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258288/414113 [00:57<00:34, 4549.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258745/414113 [00:57<00:34, 4555.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259201/414113 [00:57<00:34, 4518.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259655/414113 [00:57<00:34, 4525.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260114/414113 [00:57<00:33, 4541.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260582/414113 [00:57<00:33, 4580.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261041/414113 [00:57<00:33, 4565.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261508/414113 [00:57<00:33, 4595.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261969/414113 [00:57<00:33, 4599.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262430/414113 [00:57<00:33, 4536.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262884/414113 [00:58<00:33, 4534.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263338/414113 [00:58<00:33, 4449.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263790/414113 [00:58<00:33, 4468.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264245/414113 [00:58<00:33, 4491.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264695/414113 [00:58<00:33, 4452.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265141/414113 [00:58<00:33, 4427.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265584/414113 [00:58<00:33, 4383.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266023/414113 [00:58<00:33, 4378.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266462/414113 [00:58<00:33, 4373.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266915/414113 [00:58<00:33, 4417.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267364/414113 [00:59<00:33, 4436.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267808/414113 [00:59<00:33, 4423.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268268/414113 [00:59<00:32, 4473.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268720/414113 [00:59<00:32, 4484.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269175/414113 [00:59<00:32, 4502.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269626/414113 [00:59<00:32, 4495.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270076/414113 [00:59<00:32, 4451.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270529/414113 [00:59<00:32, 4474.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270984/414113 [00:59<00:31, 4495.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271434/414113 [00:59<00:31, 4486.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271883/414113 [01:00<00:31, 4462.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272334/414113 [01:00<00:31, 4475.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272800/414113 [01:00<00:31, 4528.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273255/414113 [01:00<00:31, 4534.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273718/414113 [01:00<00:30, 4560.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 274175/414113 [01:00<00:30, 4536.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 274629/414113 [01:00<00:30, 4529.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 275083/414113 [01:00<00:31, 4464.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 275530/414113 [01:00<00:31, 4453.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 275976/414113 [01:00<00:31, 4383.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276425/414113 [01:01<00:31, 4413.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276882/414113 [01:01<00:30, 4458.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277329/414113 [01:01<00:30, 4461.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277787/414113 [01:01<00:30, 4495.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278239/414113 [01:01<00:30, 4502.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278690/414113 [01:01<00:30, 4481.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 279139/414113 [01:01<00:30, 4465.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 279587/414113 [01:01<00:30, 4469.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280034/414113 [01:01<00:30, 4428.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280477/414113 [01:01<00:30, 4412.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280931/414113 [01:02<00:29, 4447.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281376/414113 [01:02<00:29, 4444.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281821/414113 [01:02<00:29, 4442.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282279/414113 [01:02<00:29, 4481.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282741/414113 [01:02<00:29, 4521.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 283196/414113 [01:02<00:28, 4526.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 283649/414113 [01:02<00:28, 4523.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 284102/414113 [01:02<00:28, 4497.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 284552/414113 [01:02<00:29, 4465.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285007/414113 [01:02<00:28, 4489.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285463/414113 [01:03<00:28, 4509.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285926/414113 [01:03<00:28, 4543.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286381/414113 [01:03<00:28, 4510.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286833/414113 [01:03<00:28, 4431.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 287277/414113 [01:03<00:28, 4419.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 287741/414113 [01:03<00:28, 4480.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288191/414113 [01:03<00:28, 4483.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288640/414113 [01:03<00:28, 4476.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 289088/414113 [01:03<00:27, 4467.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 289543/414113 [01:03<00:27, 4488.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 289994/414113 [01:04<00:27, 4493.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290458/414113 [01:04<00:27, 4536.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290919/414113 [01:04<00:27, 4555.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 291378/414113 [01:04<00:26, 4564.21it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 291835/414113 [01:04<00:26, 4552.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292293/414113 [01:04<00:26, 4559.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292749/414113 [01:04<00:26, 4551.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293219/414113 [01:04<00:26, 4593.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293679/414113 [01:04<00:26, 4574.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294137/414113 [01:04<00:26, 4574.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294600/414113 [01:05<00:26, 4589.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295060/414113 [01:05<00:25, 4589.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295529/414113 [01:05<00:25, 4617.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295991/414113 [01:05<00:25, 4595.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296451/414113 [01:05<00:25, 4562.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296908/414113 [01:05<00:25, 4563.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297365/414113 [01:05<00:26, 4465.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297813/414113 [01:05<00:26, 4413.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298260/414113 [01:05<00:26, 4430.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298725/414113 [01:06<00:25, 4493.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299189/414113 [01:06<00:25, 4534.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299644/414113 [01:06<00:25, 4539.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 300099/414113 [01:06<00:25, 4516.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 300551/414113 [01:06<00:25, 4394.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 300996/414113 [01:06<00:25, 4408.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301438/414113 [01:06<00:25, 4390.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301888/414113 [01:06<00:25, 4420.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302331/414113 [01:06<00:25, 4404.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302772/414113 [01:06<00:25, 4391.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303226/414113 [01:07<00:25, 4434.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303670/414113 [01:07<00:24, 4434.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 304120/414113 [01:07<00:24, 4451.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 304566/414113 [01:07<00:24, 4414.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 305008/414113 [01:07<00:24, 4404.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 305461/414113 [01:07<00:24, 4440.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 305908/414113 [01:07<00:24, 4446.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306353/414113 [01:07<00:24, 4442.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306798/414113 [01:07<00:24, 4429.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307242/414113 [01:07<00:24, 4424.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307690/414113 [01:08<00:23, 4439.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 308135/414113 [01:08<00:23, 4419.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 308597/414113 [01:08<00:23, 4475.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309047/414113 [01:08<00:23, 4480.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309511/414113 [01:08<00:23, 4526.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309968/414113 [01:08<00:22, 4538.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 310423/414113 [01:08<00:23, 4495.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 310873/414113 [01:08<00:23, 4466.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311320/414113 [01:08<00:23, 4413.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311767/414113 [01:08<00:23, 4429.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 312220/414113 [01:09<00:22, 4459.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 312670/414113 [01:09<00:22, 4471.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313118/414113 [01:09<00:23, 4383.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313559/414113 [01:09<00:22, 4390.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314014/414113 [01:09<00:22, 4436.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314458/414113 [01:09<00:22, 4436.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314902/414113 [01:09<00:22, 4333.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 315348/414113 [01:09<00:22, 4369.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 315797/414113 [01:09<00:22, 4402.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 316264/414113 [01:09<00:21, 4477.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 316729/414113 [01:10<00:21, 4526.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317206/414113 [01:10<00:21, 4594.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317667/414113 [01:10<00:21, 4536.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318122/414113 [01:10<00:21, 4512.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318584/414113 [01:10<00:21, 4542.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319039/414113 [01:10<00:21, 4490.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319489/414113 [01:10<00:21, 4476.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319959/414113 [01:10<00:20, 4541.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320431/414113 [01:10<00:20, 4592.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320902/414113 [01:10<00:20, 4624.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321372/414113 [01:11<00:19, 4646.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321845/414113 [01:11<00:19, 4669.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322313/414113 [01:11<00:19, 4658.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322780/414113 [01:11<00:19, 4658.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323246/414113 [01:11<00:19, 4590.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323706/414113 [01:11<00:19, 4555.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324162/414113 [01:11<00:19, 4509.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324619/414113 [01:11<00:19, 4526.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 325077/414113 [01:11<00:19, 4540.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 325532/414113 [01:11<00:19, 4495.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 326000/414113 [01:12<00:19, 4548.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326456/414113 [01:12<00:43, 1994.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326921/414113 [01:12<00:36, 2406.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327384/414113 [01:12<00:30, 2811.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327845/414113 [01:12<00:27, 3183.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328310/414113 [01:13<00:24, 3514.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328775/414113 [01:13<00:22, 3791.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329234/414113 [01:13<00:21, 3998.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329690/414113 [01:13<00:20, 4151.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330141/414113 [01:13<00:19, 4245.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330591/414113 [01:13<00:19, 4308.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 331040/414113 [01:13<00:19, 4328.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 331486/414113 [01:13<00:18, 4350.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 331938/414113 [01:13<00:18, 4397.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332385/414113 [01:13<00:18, 4404.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332839/414113 [01:14<00:18, 4442.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 333304/414113 [01:14<00:17, 4500.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 333762/414113 [01:14<00:17, 4521.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334226/414113 [01:14<00:17, 4554.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334683/414113 [01:14<00:17, 4523.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335137/414113 [01:14<00:17, 4520.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335590/414113 [01:14<00:17, 4486.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 336040/414113 [01:14<00:17, 4482.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 336504/414113 [01:14<00:17, 4526.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 336964/414113 [01:14<00:16, 4545.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 337419/414113 [01:15<00:17, 4385.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 337874/414113 [01:15<00:17, 4432.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338321/414113 [01:15<00:17, 4443.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338772/414113 [01:15<00:16, 4460.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339219/414113 [01:15<00:16, 4450.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339672/414113 [01:15<00:16, 4473.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340120/414113 [01:15<00:16, 4431.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340580/414113 [01:15<00:16, 4478.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 341040/414113 [01:15<00:16, 4511.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 341501/414113 [01:15<00:15, 4539.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 341958/414113 [01:16<00:15, 4545.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342424/414113 [01:16<00:15, 4576.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342882/414113 [01:16<00:15, 4551.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343349/414113 [01:16<00:15, 4585.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343812/414113 [01:16<00:15, 4596.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344272/414113 [01:16<00:15, 4591.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344732/414113 [01:16<00:15, 4560.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345189/414113 [01:16<00:15, 4562.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345647/414113 [01:16<00:14, 4566.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346114/414113 [01:16<00:14, 4596.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346574/414113 [01:17<00:14, 4550.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347033/414113 [01:17<00:14, 4560.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347490/414113 [01:17<00:14, 4549.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347948/414113 [01:17<00:14, 4557.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348404/414113 [01:17<00:14, 4502.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348864/414113 [01:17<00:14, 4531.22it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 349318/414113 [01:17<00:14, 4529.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 349773/414113 [01:17<00:14, 4535.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350227/414113 [01:17<00:14, 4503.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350690/414113 [01:17<00:13, 4538.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351161/414113 [01:18<00:13, 4586.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351620/414113 [01:18<00:13, 4569.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352078/414113 [01:18<00:13, 4562.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352543/414113 [01:18<00:13, 4587.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353002/414113 [01:18<00:13, 4568.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353459/414113 [01:18<00:13, 4559.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353922/414113 [01:18<00:13, 4578.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354386/414113 [01:18<00:12, 4595.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354853/414113 [01:18<00:12, 4617.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355315/414113 [01:18<00:12, 4617.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355778/414113 [01:19<00:12, 4618.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356240/414113 [01:19<00:12, 4587.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356703/414113 [01:19<00:12, 4597.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 357163/414113 [01:19<00:12, 4577.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 357636/414113 [01:19<00:12, 4621.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 358099/414113 [01:19<00:12, 4594.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 358559/414113 [01:19<00:12, 4593.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359034/414113 [01:19<00:11, 4636.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359498/414113 [01:19<00:11, 4632.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359962/414113 [01:19<00:11, 4602.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360425/414113 [01:20<00:11, 4608.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360886/414113 [01:20<00:11, 4594.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361346/414113 [01:20<00:11, 4594.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361810/414113 [01:20<00:11, 4605.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 362271/414113 [01:20<00:11, 4600.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 362732/414113 [01:20<00:11, 4581.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363191/414113 [01:20<00:11, 4549.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363647/414113 [01:20<00:11, 4496.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364102/414113 [01:20<00:11, 4510.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364566/414113 [01:20<00:10, 4547.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365032/414113 [01:21<00:10, 4579.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365498/414113 [01:21<00:10, 4602.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365964/414113 [01:21<00:10, 4616.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 366426/414113 [01:21<00:10, 4526.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 366880/414113 [01:21<00:10, 4524.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 367333/414113 [01:21<00:10, 4506.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 367791/414113 [01:21<00:10, 4526.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368244/414113 [01:21<00:10, 4525.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368706/414113 [01:21<00:09, 4552.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369174/414113 [01:22<00:09, 4587.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369633/414113 [01:22<00:09, 4560.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 370092/414113 [01:22<00:09, 4566.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 370549/414113 [01:22<00:09, 4540.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371006/414113 [01:22<00:09, 4545.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371461/414113 [01:22<00:09, 4540.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371916/414113 [01:22<00:09, 4536.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 372370/414113 [01:22<00:09, 4523.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 372823/414113 [01:22<00:09, 4484.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373272/414113 [01:22<00:09, 4479.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373725/414113 [01:23<00:08, 4491.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374184/414113 [01:23<00:08, 4519.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374637/414113 [01:23<00:08, 4503.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375088/414113 [01:23<00:08, 4494.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375549/414113 [01:23<00:08, 4527.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376019/414113 [01:23<00:08, 4576.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376477/414113 [01:23<00:08, 4575.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376942/414113 [01:23<00:08, 4595.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377402/414113 [01:23<00:07, 4593.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377868/414113 [01:23<00:07, 4611.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378337/414113 [01:24<00:07, 4633.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378807/414113 [01:24<00:07, 4653.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379273/414113 [01:24<00:07, 4629.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379737/414113 [01:24<00:07, 4592.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380197/414113 [01:24<00:07, 4482.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380646/414113 [01:24<00:07, 4480.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381100/414113 [01:24<00:07, 4497.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381551/414113 [01:24<00:07, 4483.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382013/414113 [01:24<00:07, 4522.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382466/414113 [01:24<00:07, 4511.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382935/414113 [01:25<00:06, 4563.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383399/414113 [01:25<00:06, 4585.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383864/414113 [01:25<00:06, 4603.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384325/414113 [01:25<00:06, 4593.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384785/414113 [01:25<00:06, 4556.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385241/414113 [01:25<00:06, 4490.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385694/414113 [01:25<00:06, 4501.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386145/414113 [01:25<00:06, 4499.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386596/414113 [01:25<00:06, 4496.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 387046/414113 [01:25<00:06, 4475.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 387503/414113 [01:26<00:05, 4501.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 387960/414113 [01:26<00:05, 4521.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 388422/414113 [01:26<00:05, 4547.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 388893/414113 [01:26<00:05, 4592.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389363/414113 [01:26<00:05, 4623.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389826/414113 [01:26<00:05, 4618.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390289/414113 [01:26<00:05, 4605.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390750/414113 [01:26<00:05, 4578.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 391208/414113 [01:26<00:05, 4566.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 391671/414113 [01:26<00:04, 4585.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392134/414113 [01:27<00:04, 4597.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392598/414113 [01:27<00:04, 4608.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 393059/414113 [01:27<00:04, 4578.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 393517/414113 [01:27<00:04, 4571.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 393975/414113 [01:27<00:04, 4571.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394433/414113 [01:27<00:04, 4548.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394888/414113 [01:27<00:04, 4453.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 395343/414113 [01:27<00:04, 4480.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 395804/414113 [01:27<00:04, 4516.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396263/414113 [01:27<00:03, 4536.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396725/414113 [01:28<00:03, 4560.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397183/414113 [01:28<00:03, 4563.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397640/414113 [01:28<00:03, 4555.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 398096/414113 [01:28<00:03, 4552.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 398552/414113 [01:28<00:03, 4554.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 399009/414113 [01:28<00:03, 4556.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 399465/414113 [01:28<00:03, 4498.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 399916/414113 [01:28<00:03, 4473.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400367/414113 [01:28<00:03, 4481.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400816/414113 [01:28<00:02, 4446.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401262/414113 [01:29<00:02, 4448.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401729/414113 [01:29<00:02, 4512.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402188/414113 [01:29<00:02, 4534.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402649/414113 [01:29<00:02, 4555.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403105/414113 [01:29<00:02, 4550.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403561/414113 [01:29<00:02, 4436.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404006/414113 [01:29<00:02, 4283.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404455/414113 [01:29<00:02, 4339.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404909/414113 [01:29<00:02, 4395.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405361/414113 [01:29<00:01, 4429.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405811/414113 [01:30<00:01, 4449.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406262/414113 [01:30<00:01, 4466.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406715/414113 [01:30<00:01, 4484.13it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 407175/414113 [01:30<00:01, 4515.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 407635/414113 [01:30<00:01, 4540.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408090/414113 [01:30<00:01, 4530.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408544/414113 [01:30<00:01, 4483.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 408993/414113 [01:30<00:01, 4478.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409456/414113 [01:30<00:01, 4521.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409914/414113 [01:30<00:00, 4537.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410377/414113 [01:31<00:00, 4564.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410842/414113 [01:31<00:00, 4588.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411301/414113 [01:31<00:00, 4577.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411759/414113 [01:31<00:00, 4529.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412213/414113 [01:31<00:00, 4506.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412664/414113 [01:31<00:00, 4493.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413114/414113 [01:31<00:00, 4489.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413579/414113 [01:31<00:00, 4533.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 414039/414113 [01:31<00:00, 4551.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 414113/414113 [01:31<00:00, 4504.86it/s]\u001b[A\u001b[A"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True     # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 10             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561299368 - Epoch [1/10], Step [100/12942], Loss: 1.9723, Perplexity: 7.1873\n",
      "1561299422 - Epoch [1/10], Step [200/12942], Loss: 1.8715, Perplexity: 6.49790\n",
      "1561299530 - Epoch [1/10], Step [400/12942], Loss: 2.0310, Perplexity: 7.62166\n",
      "1561299585 - Epoch [1/10], Step [500/12942], Loss: 1.6222, Perplexity: 5.06433\n",
      "1561299639 - Epoch [1/10], Step [600/12942], Loss: 2.3281, Perplexity: 10.2589\n",
      "1561299693 - Epoch [1/10], Step [700/12942], Loss: 1.7030, Perplexity: 5.49044\n",
      "1561299747 - Epoch [1/10], Step [800/12942], Loss: 1.8576, Perplexity: 6.40821\n",
      "1561299801 - Epoch [1/10], Step [900/12942], Loss: 1.8389, Perplexity: 6.28988\n",
      "1561299855 - Epoch [1/10], Step [1000/12942], Loss: 1.7366, Perplexity: 5.6777\n",
      "1561299909 - Epoch [1/10], Step [1100/12942], Loss: 1.9056, Perplexity: 6.72374\n",
      "1561299963 - Epoch [1/10], Step [1200/12942], Loss: 2.0026, Perplexity: 7.40851\n",
      "1561300017 - Epoch [1/10], Step [1300/12942], Loss: 2.0441, Perplexity: 7.72232\n",
      "1561300072 - Epoch [1/10], Step [1400/12942], Loss: 1.8554, Perplexity: 6.39455\n",
      "1561300126 - Epoch [1/10], Step [1500/12942], Loss: 2.1058, Perplexity: 8.21403\n",
      "1561300181 - Epoch [1/10], Step [1600/12942], Loss: 1.8933, Perplexity: 6.64110\n",
      "1561300236 - Epoch [1/10], Step [1700/12942], Loss: 1.8724, Perplexity: 6.50361\n",
      "1561300290 - Epoch [1/10], Step [1800/12942], Loss: 1.6994, Perplexity: 5.47075\n",
      "1561300344 - Epoch [1/10], Step [1900/12942], Loss: 1.6174, Perplexity: 5.03987\n",
      "1561300398 - Epoch [1/10], Step [2000/12942], Loss: 1.9503, Perplexity: 7.03089\n",
      "1561300452 - Epoch [1/10], Step [2100/12942], Loss: 1.7236, Perplexity: 5.60448\n",
      "1561300505 - Epoch [1/10], Step [2200/12942], Loss: 1.8981, Perplexity: 6.67354\n",
      "1561300559 - Epoch [1/10], Step [2300/12942], Loss: 1.8170, Perplexity: 6.15359\n",
      "1561300613 - Epoch [1/10], Step [2400/12942], Loss: 2.0515, Perplexity: 7.77954\n",
      "1561300667 - Epoch [1/10], Step [2500/12942], Loss: 1.8966, Perplexity: 6.66319\n",
      "1561300721 - Epoch [1/10], Step [2600/12942], Loss: 1.7297, Perplexity: 5.63908\n",
      "1561300775 - Epoch [1/10], Step [2700/12942], Loss: 1.7866, Perplexity: 5.96896\n",
      "1561300829 - Epoch [1/10], Step [2800/12942], Loss: 1.7150, Perplexity: 5.55670\n",
      "1561300883 - Epoch [1/10], Step [2900/12942], Loss: 1.7478, Perplexity: 5.74202\n",
      "1561300938 - Epoch [1/10], Step [3000/12942], Loss: 2.1106, Perplexity: 8.25288\n",
      "1561300991 - Epoch [1/10], Step [3100/12942], Loss: 2.1325, Perplexity: 8.43607\n",
      "1561301046 - Epoch [1/10], Step [3200/12942], Loss: 1.7550, Perplexity: 5.78379\n",
      "1561301101 - Epoch [1/10], Step [3300/12942], Loss: 1.8317, Perplexity: 6.24477\n",
      "1561301154 - Epoch [1/10], Step [3400/12942], Loss: 1.9748, Perplexity: 7.20521\n",
      "1561301209 - Epoch [1/10], Step [3500/12942], Loss: 1.6951, Perplexity: 5.44718\n",
      "1561301263 - Epoch [1/10], Step [3600/12942], Loss: 1.7300, Perplexity: 5.64088\n",
      "1561301317 - Epoch [1/10], Step [3700/12942], Loss: 1.9330, Perplexity: 6.91027\n",
      "1561301371 - Epoch [1/10], Step [3800/12942], Loss: 2.0269, Perplexity: 7.59029\n",
      "1561301425 - Epoch [1/10], Step [3900/12942], Loss: 2.2385, Perplexity: 9.37906\n",
      "1561301479 - Epoch [1/10], Step [4000/12942], Loss: 2.0308, Perplexity: 7.62053\n",
      "1561301533 - Epoch [1/10], Step [4100/12942], Loss: 1.5784, Perplexity: 4.84721\n",
      "1561301588 - Epoch [1/10], Step [4200/12942], Loss: 1.6902, Perplexity: 5.42044\n",
      "1561301641 - Epoch [1/10], Step [4300/12942], Loss: 1.8278, Perplexity: 6.22028\n",
      "1561301696 - Epoch [1/10], Step [4400/12942], Loss: 2.1110, Perplexity: 8.25654\n",
      "1561301750 - Epoch [1/10], Step [4500/12942], Loss: 1.8583, Perplexity: 6.41306\n",
      "1561301804 - Epoch [1/10], Step [4600/12942], Loss: 1.8285, Perplexity: 6.22486\n",
      "1561301858 - Epoch [1/10], Step [4700/12942], Loss: 1.7958, Perplexity: 6.02426\n",
      "1561301912 - Epoch [1/10], Step [4800/12942], Loss: 1.8480, Perplexity: 6.34716\n",
      "1561301966 - Epoch [1/10], Step [4900/12942], Loss: 1.8914, Perplexity: 6.62884\n",
      "1561302021 - Epoch [1/10], Step [5000/12942], Loss: 1.7857, Perplexity: 5.96375\n",
      "1561302075 - Epoch [1/10], Step [5100/12942], Loss: 1.8768, Perplexity: 6.53251\n",
      "1561302129 - Epoch [1/10], Step [5200/12942], Loss: 2.2155, Perplexity: 9.16570\n",
      "1561302183 - Epoch [1/10], Step [5300/12942], Loss: 1.9285, Perplexity: 6.87954\n",
      "1561302238 - Epoch [1/10], Step [5400/12942], Loss: 1.7852, Perplexity: 5.96095\n",
      "1561302292 - Epoch [1/10], Step [5500/12942], Loss: 1.7932, Perplexity: 6.00896\n",
      "1561302346 - Epoch [1/10], Step [5600/12942], Loss: 1.9642, Perplexity: 7.12954\n",
      "1561302400 - Epoch [1/10], Step [5700/12942], Loss: 1.8633, Perplexity: 6.44503\n",
      "1561302454 - Epoch [1/10], Step [5800/12942], Loss: 1.6502, Perplexity: 5.20813\n",
      "1561302508 - Epoch [1/10], Step [5900/12942], Loss: 1.6782, Perplexity: 5.35586\n",
      "1561302562 - Epoch [1/10], Step [6000/12942], Loss: 1.9141, Perplexity: 6.78091\n",
      "1561302616 - Epoch [1/10], Step [6100/12942], Loss: 1.9197, Perplexity: 6.81871\n",
      "1561302670 - Epoch [1/10], Step [6200/12942], Loss: 1.5802, Perplexity: 4.85614\n",
      "1561302724 - Epoch [1/10], Step [6300/12942], Loss: 1.6898, Perplexity: 5.41841\n",
      "1561302778 - Epoch [1/10], Step [6400/12942], Loss: 1.7064, Perplexity: 5.50937\n",
      "1561302832 - Epoch [1/10], Step [6500/12942], Loss: 1.9287, Perplexity: 6.88052\n",
      "1561302886 - Epoch [1/10], Step [6600/12942], Loss: 1.9208, Perplexity: 6.82616\n",
      "1561302940 - Epoch [1/10], Step [6700/12942], Loss: 1.9050, Perplexity: 6.71941\n",
      "1561302994 - Epoch [1/10], Step [6800/12942], Loss: 1.6902, Perplexity: 5.42053\n",
      "1561303049 - Epoch [1/10], Step [6900/12942], Loss: 1.6368, Perplexity: 5.13860\n",
      "1561303103 - Epoch [1/10], Step [7000/12942], Loss: 1.7656, Perplexity: 5.8449\n",
      "1561303157 - Epoch [1/10], Step [7100/12942], Loss: 1.6668, Perplexity: 5.29520\n",
      "1561303211 - Epoch [1/10], Step [7200/12942], Loss: 1.6968, Perplexity: 5.45678\n",
      "1561303265 - Epoch [1/10], Step [7300/12942], Loss: 1.8485, Perplexity: 6.35027\n",
      "1561303320 - Epoch [1/10], Step [7400/12942], Loss: 1.6985, Perplexity: 5.46583\n",
      "1561303374 - Epoch [1/10], Step [7500/12942], Loss: 1.9031, Perplexity: 6.70705\n",
      "1561303428 - Epoch [1/10], Step [7600/12942], Loss: 2.0380, Perplexity: 7.674900\n",
      "1561303482 - Epoch [1/10], Step [7700/12942], Loss: 2.1411, Perplexity: 8.50905\n",
      "1561303536 - Epoch [1/10], Step [7800/12942], Loss: 2.0464, Perplexity: 7.74007\n",
      "1561303589 - Epoch [1/10], Step [7900/12942], Loss: 2.1143, Perplexity: 8.28363\n",
      "1561303644 - Epoch [1/10], Step [8000/12942], Loss: 1.9358, Perplexity: 6.92994\n",
      "1561303698 - Epoch [1/10], Step [8100/12942], Loss: 1.7897, Perplexity: 5.98798\n",
      "1561303752 - Epoch [1/10], Step [8200/12942], Loss: 1.8222, Perplexity: 6.18556\n",
      "1561303806 - Epoch [1/10], Step [8300/12942], Loss: 1.6698, Perplexity: 5.31123\n",
      "1561303860 - Epoch [1/10], Step [8400/12942], Loss: 1.7818, Perplexity: 5.94044\n",
      "1561303914 - Epoch [1/10], Step [8500/12942], Loss: 2.3289, Perplexity: 10.2670\n",
      "1561303968 - Epoch [1/10], Step [8600/12942], Loss: 1.7003, Perplexity: 5.47567\n",
      "1561304023 - Epoch [1/10], Step [8700/12942], Loss: 2.1554, Perplexity: 8.63124\n",
      "1561304077 - Epoch [1/10], Step [8800/12942], Loss: 1.9457, Perplexity: 6.99834\n",
      "1561304131 - Epoch [1/10], Step [8900/12942], Loss: 1.6359, Perplexity: 5.13407\n",
      "1561304185 - Epoch [1/10], Step [9000/12942], Loss: 2.0814, Perplexity: 8.01568\n",
      "1561304239 - Epoch [1/10], Step [9100/12942], Loss: 1.6167, Perplexity: 5.03652\n",
      "1561304294 - Epoch [1/10], Step [9200/12942], Loss: 2.3206, Perplexity: 10.1818\n",
      "1561304348 - Epoch [1/10], Step [9300/12942], Loss: 1.7206, Perplexity: 5.58810\n",
      "1561304402 - Epoch [1/10], Step [9400/12942], Loss: 1.7975, Perplexity: 6.03449\n",
      "1561304456 - Epoch [1/10], Step [9500/12942], Loss: 2.0169, Perplexity: 7.51505\n",
      "1561304510 - Epoch [1/10], Step [9600/12942], Loss: 2.2345, Perplexity: 9.34166\n",
      "1561304564 - Epoch [1/10], Step [9700/12942], Loss: 2.0286, Perplexity: 7.60381\n",
      "1561304618 - Epoch [1/10], Step [9800/12942], Loss: 1.9305, Perplexity: 6.89313\n",
      "1561304672 - Epoch [1/10], Step [9900/12942], Loss: 1.9527, Perplexity: 7.04776\n",
      "1561304727 - Epoch [1/10], Step [10000/12942], Loss: 1.7940, Perplexity: 6.0134\n",
      "1561304781 - Epoch [1/10], Step [10100/12942], Loss: 2.0662, Perplexity: 7.89444\n",
      "1561304835 - Epoch [1/10], Step [10200/12942], Loss: 1.8566, Perplexity: 6.40210\n",
      "1561304890 - Epoch [1/10], Step [10300/12942], Loss: 1.9579, Perplexity: 7.08431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561304945 - Epoch [1/10], Step [10400/12942], Loss: 1.7506, Perplexity: 5.75807\n",
      "1561304999 - Epoch [1/10], Step [10500/12942], Loss: 1.6100, Perplexity: 5.00267\n",
      "1561305053 - Epoch [1/10], Step [10600/12942], Loss: 1.7299, Perplexity: 5.64038\n",
      "1561305107 - Epoch [1/10], Step [10700/12942], Loss: 2.7920, Perplexity: 16.3136\n",
      "1561305161 - Epoch [1/10], Step [10800/12942], Loss: 1.8784, Perplexity: 6.54335\n",
      "1561305215 - Epoch [1/10], Step [10900/12942], Loss: 2.0453, Perplexity: 7.73121\n",
      "1561305269 - Epoch [1/10], Step [11000/12942], Loss: 1.6714, Perplexity: 5.31988\n",
      "1561305323 - Epoch [1/10], Step [11100/12942], Loss: 2.0146, Perplexity: 7.49768\n",
      "1561305377 - Epoch [1/10], Step [11200/12942], Loss: 1.8416, Perplexity: 6.30652\n",
      "1561305432 - Epoch [1/10], Step [11300/12942], Loss: 1.8218, Perplexity: 6.18274\n",
      "1561305486 - Epoch [1/10], Step [11400/12942], Loss: 1.7450, Perplexity: 5.72590\n",
      "1561305539 - Epoch [1/10], Step [11500/12942], Loss: 1.8378, Perplexity: 6.28251\n",
      "1561305593 - Epoch [1/10], Step [11600/12942], Loss: 1.8397, Perplexity: 6.29463\n",
      "1561305648 - Epoch [1/10], Step [11700/12942], Loss: 1.9830, Perplexity: 7.26410\n",
      "1561305702 - Epoch [1/10], Step [11800/12942], Loss: 1.8134, Perplexity: 6.13145\n",
      "1561305757 - Epoch [1/10], Step [11900/12942], Loss: 1.6497, Perplexity: 5.20559\n",
      "1561305812 - Epoch [1/10], Step [12000/12942], Loss: 1.6828, Perplexity: 5.38065\n",
      "1561305866 - Epoch [1/10], Step [12100/12942], Loss: 1.9377, Perplexity: 6.94252\n",
      "1561305921 - Epoch [1/10], Step [12200/12942], Loss: 1.8957, Perplexity: 6.65692\n",
      "1561305975 - Epoch [1/10], Step [12300/12942], Loss: 1.9912, Perplexity: 7.32422\n",
      "1561306029 - Epoch [1/10], Step [12400/12942], Loss: 1.9674, Perplexity: 7.15236\n",
      "1561306084 - Epoch [1/10], Step [12500/12942], Loss: 1.7237, Perplexity: 5.60537\n",
      "1561306138 - Epoch [1/10], Step [12600/12942], Loss: 1.9442, Perplexity: 6.98778\n",
      "1561306192 - Epoch [1/10], Step [12700/12942], Loss: 1.8639, Perplexity: 6.44884\n",
      "1561306246 - Epoch [1/10], Step [12800/12942], Loss: 2.3332, Perplexity: 10.3104\n",
      "1561306300 - Epoch [1/10], Step [12900/12942], Loss: 2.6892, Perplexity: 14.7192\n",
      "1561306377 - Epoch [2/10], Step [100/12942], Loss: 1.7785, Perplexity: 5.9208973\n",
      "1561306431 - Epoch [2/10], Step [200/12942], Loss: 1.5735, Perplexity: 4.82342\n",
      "1561306485 - Epoch [2/10], Step [300/12942], Loss: 1.9870, Perplexity: 7.29387\n",
      "1561306538 - Epoch [2/10], Step [400/12942], Loss: 1.7849, Perplexity: 5.95905\n",
      "1561306592 - Epoch [2/10], Step [500/12942], Loss: 1.8328, Perplexity: 6.25137\n",
      "1561306646 - Epoch [2/10], Step [600/12942], Loss: 1.8117, Perplexity: 6.12109\n",
      "1561306701 - Epoch [2/10], Step [700/12942], Loss: 1.4685, Perplexity: 4.34261\n",
      "1561306755 - Epoch [2/10], Step [800/12942], Loss: 2.2045, Perplexity: 9.06603\n",
      "1561306809 - Epoch [2/10], Step [900/12942], Loss: 1.8544, Perplexity: 6.38812\n",
      "1561306863 - Epoch [2/10], Step [1000/12942], Loss: 1.8206, Perplexity: 6.1753\n",
      "1561306917 - Epoch [2/10], Step [1100/12942], Loss: 1.8980, Perplexity: 6.67249\n",
      "1561306971 - Epoch [2/10], Step [1200/12942], Loss: 1.9123, Perplexity: 6.76902\n",
      "1561307025 - Epoch [2/10], Step [1300/12942], Loss: 1.9027, Perplexity: 6.70419\n",
      "1561307079 - Epoch [2/10], Step [1400/12942], Loss: 1.6515, Perplexity: 5.21488\n",
      "1561307133 - Epoch [2/10], Step [1500/12942], Loss: 1.8456, Perplexity: 6.33173\n",
      "1561307188 - Epoch [2/10], Step [1600/12942], Loss: 1.8063, Perplexity: 6.08766\n",
      "1561307242 - Epoch [2/10], Step [1700/12942], Loss: 2.3002, Perplexity: 9.97584\n",
      "1561307295 - Epoch [2/10], Step [1800/12942], Loss: 1.6313, Perplexity: 5.11072\n",
      "1561307349 - Epoch [2/10], Step [1900/12942], Loss: 1.7225, Perplexity: 5.59874\n",
      "1561307403 - Epoch [2/10], Step [2000/12942], Loss: 1.8829, Perplexity: 6.57260\n",
      "1561307457 - Epoch [2/10], Step [2100/12942], Loss: 1.6216, Perplexity: 5.06129\n",
      "1561307511 - Epoch [2/10], Step [2200/12942], Loss: 2.4133, Perplexity: 11.1704\n",
      "1561307565 - Epoch [2/10], Step [2300/12942], Loss: 1.7672, Perplexity: 5.85421\n",
      "1561307619 - Epoch [2/10], Step [2400/12942], Loss: 1.6701, Perplexity: 5.31291\n",
      "1561307672 - Epoch [2/10], Step [2500/12942], Loss: 1.7142, Perplexity: 5.55228\n",
      "1561307727 - Epoch [2/10], Step [2600/12942], Loss: 1.7840, Perplexity: 5.95379\n",
      "1561307780 - Epoch [2/10], Step [2700/12942], Loss: 1.9517, Perplexity: 7.04086\n",
      "1561307834 - Epoch [2/10], Step [2800/12942], Loss: 1.9925, Perplexity: 7.33390\n",
      "1561307888 - Epoch [2/10], Step [2900/12942], Loss: 1.7540, Perplexity: 5.77770\n",
      "1561307942 - Epoch [2/10], Step [3000/12942], Loss: 1.7211, Perplexity: 5.59090\n",
      "1561307996 - Epoch [2/10], Step [3100/12942], Loss: 1.8832, Perplexity: 6.57484\n",
      "1561308051 - Epoch [2/10], Step [3200/12942], Loss: 1.5176, Perplexity: 4.56153\n",
      "1561308105 - Epoch [2/10], Step [3300/12942], Loss: 1.7741, Perplexity: 5.89499\n",
      "1561308159 - Epoch [2/10], Step [3400/12942], Loss: 1.9354, Perplexity: 6.92708\n",
      "1561308213 - Epoch [2/10], Step [3500/12942], Loss: 1.7733, Perplexity: 5.89009\n",
      "1561308267 - Epoch [2/10], Step [3600/12942], Loss: 1.6382, Perplexity: 5.14594\n",
      "1561308321 - Epoch [2/10], Step [3700/12942], Loss: 1.6240, Perplexity: 5.07346\n",
      "1561308375 - Epoch [2/10], Step [3800/12942], Loss: 1.8336, Perplexity: 6.25666\n",
      "1561308429 - Epoch [2/10], Step [3900/12942], Loss: 1.9784, Perplexity: 7.23154\n",
      "1561308483 - Epoch [2/10], Step [4000/12942], Loss: 1.8950, Perplexity: 6.65229\n",
      "1561308537 - Epoch [2/10], Step [4100/12942], Loss: 1.7409, Perplexity: 5.70264\n",
      "1561308591 - Epoch [2/10], Step [4200/12942], Loss: 2.1088, Perplexity: 8.23806\n",
      "1561308646 - Epoch [2/10], Step [4300/12942], Loss: 1.8779, Perplexity: 6.53970\n",
      "1561308700 - Epoch [2/10], Step [4400/12942], Loss: 1.7676, Perplexity: 5.85693\n",
      "1561308753 - Epoch [2/10], Step [4500/12942], Loss: 2.1516, Perplexity: 8.59859\n",
      "1561308808 - Epoch [2/10], Step [4600/12942], Loss: 1.7554, Perplexity: 5.78568\n",
      "1561308863 - Epoch [2/10], Step [4700/12942], Loss: 1.9354, Perplexity: 6.92704\n",
      "1561308917 - Epoch [2/10], Step [4800/12942], Loss: 1.8114, Perplexity: 6.11901\n",
      "1561308971 - Epoch [2/10], Step [4900/12942], Loss: 1.8995, Perplexity: 6.68268\n",
      "1561309025 - Epoch [2/10], Step [5000/12942], Loss: 2.4953, Perplexity: 12.1254\n",
      "1561309079 - Epoch [2/10], Step [5100/12942], Loss: 1.9226, Perplexity: 6.83861\n",
      "1561309133 - Epoch [2/10], Step [5200/12942], Loss: 1.9943, Perplexity: 7.3472\n",
      "1561309187 - Epoch [2/10], Step [5300/12942], Loss: 1.8302, Perplexity: 6.23515\n",
      "1561309241 - Epoch [2/10], Step [5400/12942], Loss: 1.7959, Perplexity: 6.02469\n",
      "1561309295 - Epoch [2/10], Step [5500/12942], Loss: 2.3864, Perplexity: 10.8745\n",
      "1561309348 - Epoch [2/10], Step [5600/12942], Loss: 1.6623, Perplexity: 5.27136\n",
      "1561309402 - Epoch [2/10], Step [5700/12942], Loss: 1.7951, Perplexity: 6.01984\n",
      "1561309456 - Epoch [2/10], Step [5800/12942], Loss: 2.0676, Perplexity: 7.90606\n",
      "1561309510 - Epoch [2/10], Step [5900/12942], Loss: 1.7892, Perplexity: 5.98456\n",
      "1561309564 - Epoch [2/10], Step [6000/12942], Loss: 1.7825, Perplexity: 5.94455\n",
      "1561309618 - Epoch [2/10], Step [6100/12942], Loss: 1.7609, Perplexity: 5.81787\n",
      "1561309672 - Epoch [2/10], Step [6200/12942], Loss: 1.9226, Perplexity: 6.83847\n",
      "1561309726 - Epoch [2/10], Step [6300/12942], Loss: 1.7233, Perplexity: 5.60273\n",
      "1561309780 - Epoch [2/10], Step [6400/12942], Loss: 1.6448, Perplexity: 5.18025\n",
      "1561309834 - Epoch [2/10], Step [6500/12942], Loss: 1.8299, Perplexity: 6.23343\n",
      "1561309888 - Epoch [2/10], Step [6600/12942], Loss: 2.0207, Perplexity: 7.54340\n",
      "1561309942 - Epoch [2/10], Step [6700/12942], Loss: 1.9073, Perplexity: 6.73506\n",
      "1561309996 - Epoch [2/10], Step [6800/12942], Loss: 1.8201, Perplexity: 6.17235\n",
      "1561310050 - Epoch [2/10], Step [6900/12942], Loss: 1.6702, Perplexity: 5.31309\n",
      "1561310104 - Epoch [2/10], Step [7000/12942], Loss: 1.9952, Perplexity: 7.35405\n",
      "1561310158 - Epoch [2/10], Step [7100/12942], Loss: 3.0352, Perplexity: 20.8053\n",
      "1561310212 - Epoch [2/10], Step [7200/12942], Loss: 1.9744, Perplexity: 7.20239\n",
      "1561310266 - Epoch [2/10], Step [7300/12942], Loss: 1.7779, Perplexity: 5.91779\n",
      "1561310320 - Epoch [2/10], Step [7400/12942], Loss: 1.7663, Perplexity: 5.84931\n",
      "1561310374 - Epoch [2/10], Step [7500/12942], Loss: 1.9894, Perplexity: 7.31093\n",
      "1561310428 - Epoch [2/10], Step [7600/12942], Loss: 1.7676, Perplexity: 5.85683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561310483 - Epoch [2/10], Step [7700/12942], Loss: 3.8439, Perplexity: 46.7083\n",
      "1561310537 - Epoch [2/10], Step [7800/12942], Loss: 1.7289, Perplexity: 5.63458\n",
      "1561310591 - Epoch [2/10], Step [7900/12942], Loss: 2.2490, Perplexity: 9.47782\n",
      "1561310644 - Epoch [2/10], Step [8000/12942], Loss: 2.1308, Perplexity: 8.42132\n",
      "1561310699 - Epoch [2/10], Step [8100/12942], Loss: 1.8629, Perplexity: 6.4424\n",
      "1561310752 - Epoch [2/10], Step [8200/12942], Loss: 2.0010, Perplexity: 7.39668\n",
      "1561310806 - Epoch [2/10], Step [8300/12942], Loss: 1.8956, Perplexity: 6.65654\n",
      "1561310861 - Epoch [2/10], Step [8400/12942], Loss: 1.8088, Perplexity: 6.103388\n",
      "1561310915 - Epoch [2/10], Step [8500/12942], Loss: 1.6271, Perplexity: 5.08922\n",
      "1561310969 - Epoch [2/10], Step [8600/12942], Loss: 1.8338, Perplexity: 6.25730\n",
      "1561311023 - Epoch [2/10], Step [8700/12942], Loss: 1.7696, Perplexity: 5.86863\n",
      "1561311077 - Epoch [2/10], Step [8800/12942], Loss: 1.6414, Perplexity: 5.16223\n",
      "1561311131 - Epoch [2/10], Step [8900/12942], Loss: 1.9383, Perplexity: 6.94710\n",
      "1561311185 - Epoch [2/10], Step [9000/12942], Loss: 1.9602, Perplexity: 7.10077\n",
      "1561311239 - Epoch [2/10], Step [9100/12942], Loss: 2.0264, Perplexity: 7.58686\n",
      "1561311294 - Epoch [2/10], Step [9200/12942], Loss: 1.6985, Perplexity: 5.46582\n",
      "1561311348 - Epoch [2/10], Step [9300/12942], Loss: 1.6499, Perplexity: 5.20634\n",
      "1561311403 - Epoch [2/10], Step [9400/12942], Loss: 1.7746, Perplexity: 5.89777\n",
      "1561311457 - Epoch [2/10], Step [9500/12942], Loss: 2.1724, Perplexity: 8.77918\n",
      "1561311510 - Epoch [2/10], Step [9600/12942], Loss: 1.8257, Perplexity: 6.20702\n",
      "1561311564 - Epoch [2/10], Step [9700/12942], Loss: 2.0216, Perplexity: 7.55033\n",
      "1561311618 - Epoch [2/10], Step [9800/12942], Loss: 2.2451, Perplexity: 9.44163\n",
      "1561311672 - Epoch [2/10], Step [9900/12942], Loss: 1.7566, Perplexity: 5.79295\n",
      "1561311726 - Epoch [2/10], Step [10000/12942], Loss: 1.6692, Perplexity: 5.3079\n",
      "1561311779 - Epoch [2/10], Step [10100/12942], Loss: 2.3949, Perplexity: 10.9670\n",
      "1561311833 - Epoch [2/10], Step [10200/12942], Loss: 1.8113, Perplexity: 6.11847\n",
      "1561311888 - Epoch [2/10], Step [10300/12942], Loss: 2.0656, Perplexity: 7.88996\n",
      "1561311942 - Epoch [2/10], Step [10400/12942], Loss: 1.7648, Perplexity: 5.84067\n",
      "1561311995 - Epoch [2/10], Step [10500/12942], Loss: 1.7965, Perplexity: 6.028772\n",
      "1561312049 - Epoch [2/10], Step [10600/12942], Loss: 2.0101, Perplexity: 7.463899\n",
      "1561312103 - Epoch [2/10], Step [10700/12942], Loss: 1.5784, Perplexity: 4.84701\n",
      "1561312157 - Epoch [2/10], Step [10800/12942], Loss: 2.6767, Perplexity: 14.5365\n",
      "1561312212 - Epoch [2/10], Step [10900/12942], Loss: 1.8641, Perplexity: 6.45012\n",
      "1561312266 - Epoch [2/10], Step [11000/12942], Loss: 1.7502, Perplexity: 5.75562\n",
      "1561312319 - Epoch [2/10], Step [11100/12942], Loss: 1.6378, Perplexity: 5.14392\n",
      "1561312373 - Epoch [2/10], Step [11200/12942], Loss: 1.8773, Perplexity: 6.53590\n",
      "1561312427 - Epoch [2/10], Step [11300/12942], Loss: 1.8309, Perplexity: 6.23945\n",
      "1561312481 - Epoch [2/10], Step [11400/12942], Loss: 1.6994, Perplexity: 5.47042\n",
      "1561312535 - Epoch [2/10], Step [11500/12942], Loss: 1.7366, Perplexity: 5.67816\n",
      "1561312589 - Epoch [2/10], Step [11600/12942], Loss: 1.9854, Perplexity: 7.28203\n",
      "1561312643 - Epoch [2/10], Step [11700/12942], Loss: 1.7302, Perplexity: 5.64162\n",
      "1561312696 - Epoch [2/10], Step [11800/12942], Loss: 2.0575, Perplexity: 7.82675\n",
      "1561312750 - Epoch [2/10], Step [11900/12942], Loss: 1.8359, Perplexity: 6.27087\n",
      "1561312804 - Epoch [2/10], Step [12000/12942], Loss: 1.6811, Perplexity: 5.37141\n",
      "1561312857 - Epoch [2/10], Step [12100/12942], Loss: 1.7901, Perplexity: 5.99038\n",
      "1561312911 - Epoch [2/10], Step [12200/12942], Loss: 2.6815, Perplexity: 14.6073\n",
      "1561312965 - Epoch [2/10], Step [12300/12942], Loss: 1.6128, Perplexity: 5.01713\n",
      "1561313019 - Epoch [2/10], Step [12400/12942], Loss: 2.1099, Perplexity: 8.24720\n",
      "1561313072 - Epoch [2/10], Step [12500/12942], Loss: 1.7753, Perplexity: 5.90220\n",
      "1561313126 - Epoch [2/10], Step [12600/12942], Loss: 1.6971, Perplexity: 5.45836\n",
      "1561313180 - Epoch [2/10], Step [12700/12942], Loss: 2.2769, Perplexity: 9.74686\n",
      "1561313234 - Epoch [2/10], Step [12800/12942], Loss: 1.9857, Perplexity: 7.28414\n",
      "1561313288 - Epoch [2/10], Step [12900/12942], Loss: 1.8538, Perplexity: 6.38438\n",
      "1561313366 - Epoch [3/10], Step [100/12942], Loss: 1.6731, Perplexity: 5.3286251\n",
      "1561313420 - Epoch [3/10], Step [200/12942], Loss: 1.7842, Perplexity: 5.95479\n",
      "1561313474 - Epoch [3/10], Step [300/12942], Loss: 1.7414, Perplexity: 5.70526\n",
      "1561313527 - Epoch [3/10], Step [400/12942], Loss: 2.0177, Perplexity: 7.52125\n",
      "1561313581 - Epoch [3/10], Step [500/12942], Loss: 1.8226, Perplexity: 6.18817\n",
      "1561313635 - Epoch [3/10], Step [600/12942], Loss: 1.6172, Perplexity: 5.03916\n",
      "1561313690 - Epoch [3/10], Step [700/12942], Loss: 1.7331, Perplexity: 5.65797\n",
      "1561313744 - Epoch [3/10], Step [800/12942], Loss: 2.1883, Perplexity: 8.92046\n",
      "1561313797 - Epoch [3/10], Step [900/12942], Loss: 1.5858, Perplexity: 4.88302\n",
      "1561313852 - Epoch [3/10], Step [1000/12942], Loss: 1.6767, Perplexity: 5.3478\n",
      "1561313906 - Epoch [3/10], Step [1100/12942], Loss: 2.0375, Perplexity: 7.67130\n",
      "1561313960 - Epoch [3/10], Step [1200/12942], Loss: 1.6515, Perplexity: 5.21485\n",
      "1561314014 - Epoch [3/10], Step [1300/12942], Loss: 1.8857, Perplexity: 6.59091\n",
      "1561314068 - Epoch [3/10], Step [1400/12942], Loss: 1.8415, Perplexity: 6.30604\n",
      "1561314123 - Epoch [3/10], Step [1500/12942], Loss: 1.7939, Perplexity: 6.01277\n",
      "1561314177 - Epoch [3/10], Step [1600/12942], Loss: 2.0078, Perplexity: 7.44670\n",
      "1561314231 - Epoch [3/10], Step [1700/12942], Loss: 1.8429, Perplexity: 6.31516\n",
      "1561314284 - Epoch [3/10], Step [1800/12942], Loss: 1.9452, Perplexity: 6.99529\n",
      "1561314338 - Epoch [3/10], Step [1900/12942], Loss: 1.9473, Perplexity: 7.00979\n",
      "1561314392 - Epoch [3/10], Step [2000/12942], Loss: 1.6500, Perplexity: 5.20714\n",
      "1561314446 - Epoch [3/10], Step [2100/12942], Loss: 1.7973, Perplexity: 6.03351\n",
      "1561314500 - Epoch [3/10], Step [2200/12942], Loss: 2.1497, Perplexity: 8.58259\n",
      "1561314554 - Epoch [3/10], Step [2300/12942], Loss: 2.2064, Perplexity: 9.08262\n",
      "1561314608 - Epoch [3/10], Step [2400/12942], Loss: 1.8133, Perplexity: 6.13098\n",
      "1561314662 - Epoch [3/10], Step [2500/12942], Loss: 1.6628, Perplexity: 5.27434\n",
      "1561314716 - Epoch [3/10], Step [2600/12942], Loss: 1.8090, Perplexity: 6.10428\n",
      "1561314770 - Epoch [3/10], Step [2700/12942], Loss: 1.5709, Perplexity: 4.8109\n",
      "1561314824 - Epoch [3/10], Step [2800/12942], Loss: 1.6279, Perplexity: 5.09307\n",
      "1561314879 - Epoch [3/10], Step [2900/12942], Loss: 1.7370, Perplexity: 5.68058\n",
      "1561314933 - Epoch [3/10], Step [3000/12942], Loss: 2.0346, Perplexity: 7.64886\n",
      "1561314987 - Epoch [3/10], Step [3100/12942], Loss: 2.3131, Perplexity: 10.1059\n",
      "1561315041 - Epoch [3/10], Step [3200/12942], Loss: 1.7393, Perplexity: 5.693442\n",
      "1561315096 - Epoch [3/10], Step [3300/12942], Loss: 1.8928, Perplexity: 6.63781\n",
      "1561315150 - Epoch [3/10], Step [3400/12942], Loss: 1.7630, Perplexity: 5.83000\n",
      "1561315204 - Epoch [3/10], Step [3500/12942], Loss: 1.9756, Perplexity: 7.21116\n",
      "1561315258 - Epoch [3/10], Step [3600/12942], Loss: 1.8595, Perplexity: 6.42043\n",
      "1561315312 - Epoch [3/10], Step [3700/12942], Loss: 1.8343, Perplexity: 6.26053\n",
      "1561315366 - Epoch [3/10], Step [3800/12942], Loss: 2.2098, Perplexity: 9.11434\n",
      "1561315419 - Epoch [3/10], Step [3900/12942], Loss: 1.7103, Perplexity: 5.53064\n",
      "1561315474 - Epoch [3/10], Step [4000/12942], Loss: 1.6912, Perplexity: 5.42638\n",
      "1561315528 - Epoch [3/10], Step [4100/12942], Loss: 1.8316, Perplexity: 6.24425\n",
      "1561315582 - Epoch [3/10], Step [4200/12942], Loss: 2.0762, Perplexity: 7.97401\n",
      "1561315636 - Epoch [3/10], Step [4300/12942], Loss: 2.2464, Perplexity: 9.45349\n",
      "1561315690 - Epoch [3/10], Step [4400/12942], Loss: 1.7216, Perplexity: 5.59361\n",
      "1561315744 - Epoch [3/10], Step [4500/12942], Loss: 2.2350, Perplexity: 9.34680\n",
      "1561315798 - Epoch [3/10], Step [4600/12942], Loss: 1.4992, Perplexity: 4.47805\n",
      "1561315852 - Epoch [3/10], Step [4700/12942], Loss: 1.6479, Perplexity: 5.19620\n",
      "1561315906 - Epoch [3/10], Step [4800/12942], Loss: 1.6813, Perplexity: 5.37241\n",
      "1561315960 - Epoch [3/10], Step [4900/12942], Loss: 1.8477, Perplexity: 6.34536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561316016 - Epoch [3/10], Step [5000/12942], Loss: 1.9428, Perplexity: 6.97804\n",
      "1561316069 - Epoch [3/10], Step [5100/12942], Loss: 1.5120, Perplexity: 4.53564\n",
      "1561316124 - Epoch [3/10], Step [5200/12942], Loss: 1.6671, Perplexity: 5.29668\n",
      "1561316178 - Epoch [3/10], Step [5300/12942], Loss: 1.8062, Perplexity: 6.08717\n",
      "1561316232 - Epoch [3/10], Step [5400/12942], Loss: 1.6214, Perplexity: 5.06035\n",
      "1561316286 - Epoch [3/10], Step [5500/12942], Loss: 2.1260, Perplexity: 8.38097\n",
      "1561316340 - Epoch [3/10], Step [5600/12942], Loss: 1.8836, Perplexity: 6.57696\n",
      "1561316394 - Epoch [3/10], Step [5700/12942], Loss: 1.9315, Perplexity: 6.89975\n",
      "1561316449 - Epoch [3/10], Step [5800/12942], Loss: 1.8645, Perplexity: 6.45307\n",
      "1561316503 - Epoch [3/10], Step [5900/12942], Loss: 2.0163, Perplexity: 7.51037\n",
      "1561316557 - Epoch [3/10], Step [6000/12942], Loss: 1.8922, Perplexity: 6.63428\n",
      "1561316611 - Epoch [3/10], Step [6100/12942], Loss: 1.7791, Perplexity: 5.92476\n",
      "1561316665 - Epoch [3/10], Step [6200/12942], Loss: 1.5714, Perplexity: 4.81318\n",
      "1561316720 - Epoch [3/10], Step [6300/12942], Loss: 1.8193, Perplexity: 6.16787\n",
      "1561316773 - Epoch [3/10], Step [6400/12942], Loss: 1.7703, Perplexity: 5.87254\n",
      "1561316828 - Epoch [3/10], Step [6500/12942], Loss: 1.6933, Perplexity: 5.43742\n",
      "1561316882 - Epoch [3/10], Step [6600/12942], Loss: 1.6867, Perplexity: 5.40166\n",
      "1561316936 - Epoch [3/10], Step [6700/12942], Loss: 1.8942, Perplexity: 6.64756\n",
      "1561316990 - Epoch [3/10], Step [6800/12942], Loss: 1.8815, Perplexity: 6.56315\n",
      "1561317044 - Epoch [3/10], Step [6900/12942], Loss: 2.4363, Perplexity: 11.4306\n",
      "1561317098 - Epoch [3/10], Step [7000/12942], Loss: 1.6877, Perplexity: 5.40722\n",
      "1561317151 - Epoch [3/10], Step [7100/12942], Loss: 1.8753, Perplexity: 6.52261\n",
      "1561317205 - Epoch [3/10], Step [7200/12942], Loss: 1.7396, Perplexity: 5.69501\n",
      "1561317259 - Epoch [3/10], Step [7300/12942], Loss: 1.6665, Perplexity: 5.29342\n",
      "1561317314 - Epoch [3/10], Step [7400/12942], Loss: 1.9954, Perplexity: 7.35503\n",
      "1561317368 - Epoch [3/10], Step [7500/12942], Loss: 1.8992, Perplexity: 6.680784\n",
      "1561317422 - Epoch [3/10], Step [7600/12942], Loss: 1.8264, Perplexity: 6.21134\n",
      "1561317476 - Epoch [3/10], Step [7700/12942], Loss: 1.9965, Perplexity: 7.36355\n",
      "1561317530 - Epoch [3/10], Step [7800/12942], Loss: 1.7907, Perplexity: 5.99341\n",
      "1561317584 - Epoch [3/10], Step [7900/12942], Loss: 1.8113, Perplexity: 6.11875\n",
      "1561317638 - Epoch [3/10], Step [8000/12942], Loss: 2.0447, Perplexity: 7.72710\n",
      "1561317692 - Epoch [3/10], Step [8100/12942], Loss: 1.7681, Perplexity: 5.85975\n",
      "1561317746 - Epoch [3/10], Step [8200/12942], Loss: 1.6624, Perplexity: 5.27220\n",
      "1561317800 - Epoch [3/10], Step [8300/12942], Loss: 1.8356, Perplexity: 6.26873\n",
      "1561317854 - Epoch [3/10], Step [8400/12942], Loss: 1.7130, Perplexity: 5.54585\n",
      "1561317908 - Epoch [3/10], Step [8500/12942], Loss: 1.7114, Perplexity: 5.53667\n",
      "1561317962 - Epoch [3/10], Step [8600/12942], Loss: 1.8321, Perplexity: 6.24738\n",
      "1561318016 - Epoch [3/10], Step [8700/12942], Loss: 2.0001, Perplexity: 7.38995\n",
      "1561318070 - Epoch [3/10], Step [8800/12942], Loss: 1.7409, Perplexity: 5.70251\n",
      "1561318124 - Epoch [3/10], Step [8900/12942], Loss: 1.7678, Perplexity: 5.85777\n",
      "1561318178 - Epoch [3/10], Step [9000/12942], Loss: 2.0051, Perplexity: 7.42699\n",
      "1561318232 - Epoch [3/10], Step [9100/12942], Loss: 1.8024, Perplexity: 6.06401\n",
      "1561318285 - Epoch [3/10], Step [9200/12942], Loss: 1.8781, Perplexity: 6.54089\n",
      "1561318339 - Epoch [3/10], Step [9300/12942], Loss: 1.9996, Perplexity: 7.38588\n",
      "1561318393 - Epoch [3/10], Step [9400/12942], Loss: 1.6876, Perplexity: 5.40677\n",
      "1561318447 - Epoch [3/10], Step [9500/12942], Loss: 1.9336, Perplexity: 6.91466\n",
      "1561318501 - Epoch [3/10], Step [9600/12942], Loss: 1.8707, Perplexity: 6.49308\n",
      "1561318555 - Epoch [3/10], Step [9700/12942], Loss: 1.8068, Perplexity: 6.09122\n",
      "1561318609 - Epoch [3/10], Step [9800/12942], Loss: 1.6823, Perplexity: 5.37810\n",
      "1561318663 - Epoch [3/10], Step [9900/12942], Loss: 2.2597, Perplexity: 9.58034\n",
      "1561318718 - Epoch [3/10], Step [10000/12942], Loss: 1.7945, Perplexity: 6.0168\n",
      "1561318772 - Epoch [3/10], Step [10100/12942], Loss: 1.9049, Perplexity: 6.71906\n",
      "1561318825 - Epoch [3/10], Step [10200/12942], Loss: 2.0594, Perplexity: 7.84140\n",
      "1561318879 - Epoch [3/10], Step [10300/12942], Loss: 1.7887, Perplexity: 5.98190\n",
      "1561318933 - Epoch [3/10], Step [10400/12942], Loss: 1.8279, Perplexity: 6.22060\n",
      "1561318987 - Epoch [3/10], Step [10500/12942], Loss: 2.0372, Perplexity: 7.66892\n",
      "1561319041 - Epoch [3/10], Step [10600/12942], Loss: 1.9607, Perplexity: 7.10416\n",
      "1561319095 - Epoch [3/10], Step [10700/12942], Loss: 2.0681, Perplexity: 7.90965\n",
      "1561319149 - Epoch [3/10], Step [10800/12942], Loss: 1.8379, Perplexity: 6.28302\n",
      "1561319202 - Epoch [3/10], Step [10900/12942], Loss: 2.0023, Perplexity: 7.40587\n",
      "1561319257 - Epoch [3/10], Step [11000/12942], Loss: 1.7535, Perplexity: 5.77493\n",
      "1561319311 - Epoch [3/10], Step [11100/12942], Loss: 1.8092, Perplexity: 6.10564\n",
      "1561319365 - Epoch [3/10], Step [11200/12942], Loss: 1.7493, Perplexity: 5.75086\n",
      "1561319419 - Epoch [3/10], Step [11300/12942], Loss: 1.7773, Perplexity: 5.91360\n",
      "1561319473 - Epoch [3/10], Step [11400/12942], Loss: 1.8572, Perplexity: 6.4060\n",
      "1561319527 - Epoch [3/10], Step [11500/12942], Loss: 1.8419, Perplexity: 6.30835\n",
      "1561319581 - Epoch [3/10], Step [11600/12942], Loss: 1.8083, Perplexity: 6.10043\n",
      "1561319635 - Epoch [3/10], Step [11700/12942], Loss: 1.8441, Perplexity: 6.32220\n",
      "1561319690 - Epoch [3/10], Step [11800/12942], Loss: 1.8059, Perplexity: 6.08579\n",
      "1561319744 - Epoch [3/10], Step [11900/12942], Loss: 2.1715, Perplexity: 8.77168\n",
      "1561319798 - Epoch [3/10], Step [12000/12942], Loss: 1.7500, Perplexity: 5.75482\n",
      "1561319852 - Epoch [3/10], Step [12100/12942], Loss: 2.0272, Perplexity: 7.59276\n",
      "1561319907 - Epoch [3/10], Step [12200/12942], Loss: 1.8355, Perplexity: 6.26838\n",
      "1561319961 - Epoch [3/10], Step [12300/12942], Loss: 1.9071, Perplexity: 6.73322\n",
      "1561320015 - Epoch [3/10], Step [12400/12942], Loss: 1.7953, Perplexity: 6.02124\n",
      "1561320069 - Epoch [3/10], Step [12500/12942], Loss: 1.7842, Perplexity: 5.95461\n",
      "1561320123 - Epoch [3/10], Step [12600/12942], Loss: 1.6442, Perplexity: 5.17710\n",
      "1561320177 - Epoch [3/10], Step [12700/12942], Loss: 1.6477, Perplexity: 5.19491\n",
      "1561320231 - Epoch [3/10], Step [12800/12942], Loss: 1.7665, Perplexity: 5.85056\n",
      "1561320284 - Epoch [3/10], Step [12900/12942], Loss: 1.8163, Perplexity: 6.14895\n",
      "1561320361 - Epoch [4/10], Step [100/12942], Loss: 1.7954, Perplexity: 6.021953\n",
      "1561320415 - Epoch [4/10], Step [200/12942], Loss: 1.9853, Perplexity: 7.28153\n",
      "1561320469 - Epoch [4/10], Step [300/12942], Loss: 1.8046, Perplexity: 6.07752\n",
      "1561320523 - Epoch [4/10], Step [400/12942], Loss: 1.5955, Perplexity: 4.93079\n",
      "1561320578 - Epoch [4/10], Step [500/12942], Loss: 1.8090, Perplexity: 6.10458\n",
      "1561320632 - Epoch [4/10], Step [600/12942], Loss: 1.7505, Perplexity: 5.75768\n",
      "1561320686 - Epoch [4/10], Step [700/12942], Loss: 1.8668, Perplexity: 6.46793\n",
      "1561320741 - Epoch [4/10], Step [800/12942], Loss: 1.6853, Perplexity: 5.39411\n",
      "1561320794 - Epoch [4/10], Step [900/12942], Loss: 2.6266, Perplexity: 13.8264\n",
      "1561320848 - Epoch [4/10], Step [1000/12942], Loss: 1.9398, Perplexity: 6.9572\n",
      "1561320902 - Epoch [4/10], Step [1100/12942], Loss: 1.7811, Perplexity: 5.93639\n",
      "1561320956 - Epoch [4/10], Step [1200/12942], Loss: 1.8246, Perplexity: 6.20016\n",
      "1561321010 - Epoch [4/10], Step [1300/12942], Loss: 1.8960, Perplexity: 6.65934\n",
      "1561321064 - Epoch [4/10], Step [1400/12942], Loss: 1.8380, Perplexity: 6.28422\n",
      "1561321117 - Epoch [4/10], Step [1500/12942], Loss: 1.7623, Perplexity: 5.82604\n",
      "1561321171 - Epoch [4/10], Step [1600/12942], Loss: 2.0372, Perplexity: 7.66923\n",
      "1561321225 - Epoch [4/10], Step [1700/12942], Loss: 1.5495, Perplexity: 4.7091\n",
      "1561321279 - Epoch [4/10], Step [1800/12942], Loss: 1.8349, Perplexity: 6.26446\n",
      "1561321333 - Epoch [4/10], Step [1900/12942], Loss: 2.1352, Perplexity: 8.45850\n",
      "1561321388 - Epoch [4/10], Step [2000/12942], Loss: 1.9017, Perplexity: 6.69734\n",
      "1561321441 - Epoch [4/10], Step [2100/12942], Loss: 1.9616, Perplexity: 7.11083\n",
      "1561321495 - Epoch [4/10], Step [2200/12942], Loss: 1.8559, Perplexity: 6.39767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561321549 - Epoch [4/10], Step [2300/12942], Loss: 2.0633, Perplexity: 7.87167\n",
      "1561321603 - Epoch [4/10], Step [2400/12942], Loss: 1.8098, Perplexity: 6.10952\n",
      "1561321657 - Epoch [4/10], Step [2500/12942], Loss: 1.8761, Perplexity: 6.52829\n",
      "1561321711 - Epoch [4/10], Step [2600/12942], Loss: 1.7312, Perplexity: 5.64737\n",
      "1561321765 - Epoch [4/10], Step [2700/12942], Loss: 1.6832, Perplexity: 5.38280\n",
      "1561321819 - Epoch [4/10], Step [2800/12942], Loss: 1.6508, Perplexity: 5.21104\n",
      "1561321873 - Epoch [4/10], Step [2900/12942], Loss: 1.7628, Perplexity: 5.82866\n",
      "1561321927 - Epoch [4/10], Step [3000/12942], Loss: 1.9727, Perplexity: 7.19033\n",
      "1561321981 - Epoch [4/10], Step [3100/12942], Loss: 1.8549, Perplexity: 6.39121\n",
      "1561322034 - Epoch [4/10], Step [3200/12942], Loss: 1.7942, Perplexity: 6.01471\n",
      "1561322089 - Epoch [4/10], Step [3300/12942], Loss: 1.9989, Perplexity: 7.38117\n",
      "1561322143 - Epoch [4/10], Step [3400/12942], Loss: 1.8120, Perplexity: 6.12268\n",
      "1561322196 - Epoch [4/10], Step [3500/12942], Loss: 1.9353, Perplexity: 6.92647\n",
      "1561322250 - Epoch [4/10], Step [3600/12942], Loss: 1.9254, Perplexity: 6.85819\n",
      "1561322304 - Epoch [4/10], Step [3700/12942], Loss: 1.9534, Perplexity: 7.05295\n",
      "1561322358 - Epoch [4/10], Step [3800/12942], Loss: 1.9201, Perplexity: 6.82178\n",
      "1561322412 - Epoch [4/10], Step [3900/12942], Loss: 1.8824, Perplexity: 6.56912\n",
      "1561322467 - Epoch [4/10], Step [4000/12942], Loss: 1.7637, Perplexity: 5.83408\n",
      "1561322521 - Epoch [4/10], Step [4100/12942], Loss: 2.2114, Perplexity: 9.12883\n",
      "1561322575 - Epoch [4/10], Step [4200/12942], Loss: 2.0636, Perplexity: 7.87465\n",
      "1561322629 - Epoch [4/10], Step [4300/12942], Loss: 1.8423, Perplexity: 6.31115\n",
      "1561322684 - Epoch [4/10], Step [4400/12942], Loss: 1.9500, Perplexity: 7.02890\n",
      "1561322738 - Epoch [4/10], Step [4500/12942], Loss: 1.7851, Perplexity: 5.96049\n",
      "1561322792 - Epoch [4/10], Step [4600/12942], Loss: 1.6608, Perplexity: 5.26342\n",
      "1561322846 - Epoch [4/10], Step [4700/12942], Loss: 2.1105, Perplexity: 8.25230\n",
      "1561322900 - Epoch [4/10], Step [4800/12942], Loss: 1.7210, Perplexity: 5.59007\n",
      "1561322953 - Epoch [4/10], Step [4900/12942], Loss: 1.7317, Perplexity: 5.65030\n",
      "1561323007 - Epoch [4/10], Step [5000/12942], Loss: 1.9495, Perplexity: 7.02496\n",
      "1561323061 - Epoch [4/10], Step [5100/12942], Loss: 1.6637, Perplexity: 5.27881\n",
      "1561323115 - Epoch [4/10], Step [5200/12942], Loss: 1.7744, Perplexity: 5.89675\n",
      "1561323169 - Epoch [4/10], Step [5300/12942], Loss: 1.7580, Perplexity: 5.80119\n",
      "1561323223 - Epoch [4/10], Step [5400/12942], Loss: 1.9179, Perplexity: 6.80661\n",
      "1561323277 - Epoch [4/10], Step [5500/12942], Loss: 1.9899, Perplexity: 7.31519\n",
      "1561323331 - Epoch [4/10], Step [5600/12942], Loss: 1.7484, Perplexity: 5.74531\n",
      "1561323385 - Epoch [4/10], Step [5700/12942], Loss: 1.8327, Perplexity: 6.25109\n",
      "1561323439 - Epoch [4/10], Step [5800/12942], Loss: 2.1539, Perplexity: 8.61823\n",
      "1561323493 - Epoch [4/10], Step [5900/12942], Loss: 1.7463, Perplexity: 5.73349\n",
      "1561323547 - Epoch [4/10], Step [6000/12942], Loss: 1.7073, Perplexity: 5.51387\n",
      "1561323601 - Epoch [4/10], Step [6100/12942], Loss: 1.7798, Perplexity: 5.92857\n",
      "1561323655 - Epoch [4/10], Step [6200/12942], Loss: 1.9164, Perplexity: 6.79629\n",
      "1561323710 - Epoch [4/10], Step [6300/12942], Loss: 1.6598, Perplexity: 5.2584\n",
      "1561323765 - Epoch [4/10], Step [6400/12942], Loss: 2.2396, Perplexity: 9.38929\n",
      "1561323819 - Epoch [4/10], Step [6500/12942], Loss: 1.8481, Perplexity: 6.34776\n",
      "1561323873 - Epoch [4/10], Step [6600/12942], Loss: 1.9251, Perplexity: 6.85564\n",
      "1561323927 - Epoch [4/10], Step [6700/12942], Loss: 2.0005, Perplexity: 7.39260\n",
      "1561323981 - Epoch [4/10], Step [6800/12942], Loss: 2.3718, Perplexity: 10.7172\n",
      "1561324035 - Epoch [4/10], Step [6900/12942], Loss: 2.1696, Perplexity: 8.75460\n",
      "1561324089 - Epoch [4/10], Step [7000/12942], Loss: 1.9760, Perplexity: 7.21399\n",
      "1561324143 - Epoch [4/10], Step [7100/12942], Loss: 1.7925, Perplexity: 6.00442\n",
      "1561324197 - Epoch [4/10], Step [7200/12942], Loss: 1.8080, Perplexity: 6.09826\n",
      "1561324251 - Epoch [4/10], Step [7300/12942], Loss: 1.8481, Perplexity: 6.34796\n",
      "1561324305 - Epoch [4/10], Step [7400/12942], Loss: 2.1042, Perplexity: 8.20096\n",
      "1561324359 - Epoch [4/10], Step [7500/12942], Loss: 1.9089, Perplexity: 6.74562\n",
      "1561324413 - Epoch [4/10], Step [7600/12942], Loss: 1.9476, Perplexity: 7.01182\n",
      "1561324467 - Epoch [4/10], Step [7700/12942], Loss: 1.9309, Perplexity: 6.89557\n",
      "1561324521 - Epoch [4/10], Step [7800/12942], Loss: 1.6643, Perplexity: 5.28198\n",
      "1561324575 - Epoch [4/10], Step [7900/12942], Loss: 2.8813, Perplexity: 17.8367\n",
      "1561324629 - Epoch [4/10], Step [8000/12942], Loss: 1.9765, Perplexity: 7.21727\n",
      "1561324683 - Epoch [4/10], Step [8100/12942], Loss: 1.8140, Perplexity: 6.13497\n",
      "1561324737 - Epoch [4/10], Step [8200/12942], Loss: 1.7767, Perplexity: 5.91020\n",
      "1561324791 - Epoch [4/10], Step [8300/12942], Loss: 1.6633, Perplexity: 5.276830\n",
      "1561324844 - Epoch [4/10], Step [8400/12942], Loss: 1.8747, Perplexity: 6.51916\n",
      "1561324898 - Epoch [4/10], Step [8500/12942], Loss: 1.6582, Perplexity: 5.25018\n",
      "1561324953 - Epoch [4/10], Step [8600/12942], Loss: 1.6849, Perplexity: 5.39188\n",
      "1561325007 - Epoch [4/10], Step [8700/12942], Loss: 1.7124, Perplexity: 5.54217\n",
      "1561325061 - Epoch [4/10], Step [8800/12942], Loss: 1.8896, Perplexity: 6.61675\n",
      "1561325115 - Epoch [4/10], Step [8900/12942], Loss: 1.9897, Perplexity: 7.31362\n",
      "1561325169 - Epoch [4/10], Step [9000/12942], Loss: 1.7076, Perplexity: 5.51571\n",
      "1561325224 - Epoch [4/10], Step [9100/12942], Loss: 1.7667, Perplexity: 5.85168\n",
      "1561325278 - Epoch [4/10], Step [9200/12942], Loss: 1.7470, Perplexity: 5.73724\n",
      "1561325332 - Epoch [4/10], Step [9300/12942], Loss: 1.5429, Perplexity: 4.67839\n",
      "1561325386 - Epoch [4/10], Step [9400/12942], Loss: 1.7134, Perplexity: 5.54787\n",
      "1561325440 - Epoch [4/10], Step [9500/12942], Loss: 2.0463, Perplexity: 7.73908\n",
      "1561325494 - Epoch [4/10], Step [9600/12942], Loss: 1.5756, Perplexity: 4.83393\n",
      "1561325548 - Epoch [4/10], Step [9700/12942], Loss: 1.5608, Perplexity: 4.76245\n",
      "1561325602 - Epoch [4/10], Step [9800/12942], Loss: 1.6335, Perplexity: 5.12192\n",
      "1561325656 - Epoch [4/10], Step [9900/12942], Loss: 1.6287, Perplexity: 5.09717\n",
      "1561325710 - Epoch [4/10], Step [10000/12942], Loss: 1.8780, Perplexity: 6.5405\n",
      "1561325764 - Epoch [4/10], Step [10100/12942], Loss: 1.7661, Perplexity: 5.84818\n",
      "1561325818 - Epoch [4/10], Step [10200/12942], Loss: 1.7121, Perplexity: 5.54044\n",
      "1561325873 - Epoch [4/10], Step [10300/12942], Loss: 1.8642, Perplexity: 6.4509\n",
      "1561325927 - Epoch [4/10], Step [10400/12942], Loss: 2.0788, Perplexity: 7.99525\n",
      "1561325981 - Epoch [4/10], Step [10500/12942], Loss: 1.8625, Perplexity: 6.43965\n",
      "1561326035 - Epoch [4/10], Step [10600/12942], Loss: 1.9498, Perplexity: 7.02767\n",
      "1561326089 - Epoch [4/10], Step [10700/12942], Loss: 1.8591, Perplexity: 6.41786\n",
      "1561326144 - Epoch [4/10], Step [10800/12942], Loss: 2.2127, Perplexity: 9.14074\n",
      "1561326199 - Epoch [4/10], Step [10900/12942], Loss: 1.8859, Perplexity: 6.59213\n",
      "1561326253 - Epoch [4/10], Step [11000/12942], Loss: 1.5798, Perplexity: 4.85404\n",
      "1561326307 - Epoch [4/10], Step [11100/12942], Loss: 1.8317, Perplexity: 6.24463\n",
      "1561326361 - Epoch [4/10], Step [11200/12942], Loss: 1.8583, Perplexity: 6.41285\n",
      "1561326415 - Epoch [4/10], Step [11300/12942], Loss: 1.8364, Perplexity: 6.27391\n",
      "1561326469 - Epoch [4/10], Step [11400/12942], Loss: 1.7009, Perplexity: 5.47869\n",
      "1561326523 - Epoch [4/10], Step [11500/12942], Loss: 1.4792, Perplexity: 4.38930\n",
      "1561326577 - Epoch [4/10], Step [11600/12942], Loss: 1.8650, Perplexity: 6.45628\n",
      "1561326631 - Epoch [4/10], Step [11700/12942], Loss: 1.5166, Perplexity: 4.55655\n",
      "1561326685 - Epoch [4/10], Step [11800/12942], Loss: 1.8894, Perplexity: 6.61577\n",
      "1561326739 - Epoch [4/10], Step [11900/12942], Loss: 1.7235, Perplexity: 5.60399\n",
      "1561326793 - Epoch [4/10], Step [12000/12942], Loss: 1.8551, Perplexity: 6.39228\n",
      "1561326847 - Epoch [4/10], Step [12100/12942], Loss: 1.5211, Perplexity: 4.57734\n",
      "1561326901 - Epoch [4/10], Step [12200/12942], Loss: 1.7181, Perplexity: 5.57401\n",
      "1561326956 - Epoch [4/10], Step [12300/12942], Loss: 1.8416, Perplexity: 6.30652\n",
      "1561327010 - Epoch [4/10], Step [12400/12942], Loss: 1.9192, Perplexity: 6.81529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561327064 - Epoch [4/10], Step [12500/12942], Loss: 1.8098, Perplexity: 6.10959\n",
      "1561327118 - Epoch [4/10], Step [12600/12942], Loss: 1.7587, Perplexity: 5.80504\n",
      "1561327172 - Epoch [4/10], Step [12700/12942], Loss: 1.6962, Perplexity: 5.45320\n",
      "1561327226 - Epoch [4/10], Step [12800/12942], Loss: 1.5349, Perplexity: 4.64087\n",
      "1561327280 - Epoch [4/10], Step [12900/12942], Loss: 1.6528, Perplexity: 5.22180\n",
      "1561327357 - Epoch [5/10], Step [100/12942], Loss: 1.8942, Perplexity: 6.6470537\n",
      "1561327411 - Epoch [5/10], Step [200/12942], Loss: 2.0601, Perplexity: 7.84700\n",
      "1561327465 - Epoch [5/10], Step [300/12942], Loss: 1.7814, Perplexity: 5.93841\n",
      "1561327519 - Epoch [5/10], Step [400/12942], Loss: 1.8394, Perplexity: 6.29300\n",
      "1561327574 - Epoch [5/10], Step [500/12942], Loss: 1.6944, Perplexity: 5.44322\n",
      "1561327628 - Epoch [5/10], Step [600/12942], Loss: 2.5149, Perplexity: 12.3652\n",
      "1561327681 - Epoch [5/10], Step [700/12942], Loss: 2.6410, Perplexity: 14.0270\n",
      "1561327735 - Epoch [5/10], Step [800/12942], Loss: 1.9296, Perplexity: 6.88660\n",
      "1561327790 - Epoch [5/10], Step [900/12942], Loss: 1.9554, Perplexity: 7.06709\n",
      "1561327844 - Epoch [5/10], Step [1000/12942], Loss: 2.5675, Perplexity: 13.0338\n",
      "1561327897 - Epoch [5/10], Step [1100/12942], Loss: 1.9771, Perplexity: 7.22206\n",
      "1561327951 - Epoch [5/10], Step [1200/12942], Loss: 1.5828, Perplexity: 4.86881\n",
      "1561328005 - Epoch [5/10], Step [1300/12942], Loss: 1.5837, Perplexity: 4.87307\n",
      "1561328059 - Epoch [5/10], Step [1400/12942], Loss: 1.8127, Perplexity: 6.12721\n",
      "1561328113 - Epoch [5/10], Step [1500/12942], Loss: 1.6090, Perplexity: 4.9976\n",
      "1561328167 - Epoch [5/10], Step [1600/12942], Loss: 1.9462, Perplexity: 7.00217\n",
      "1561328222 - Epoch [5/10], Step [1700/12942], Loss: 1.5968, Perplexity: 4.93726\n",
      "1561328276 - Epoch [5/10], Step [1800/12942], Loss: 1.8956, Perplexity: 6.65668\n",
      "1561328330 - Epoch [5/10], Step [1900/12942], Loss: 1.8673, Perplexity: 6.47091\n",
      "1561328384 - Epoch [5/10], Step [2000/12942], Loss: 1.9134, Perplexity: 6.7759\n",
      "1561328438 - Epoch [5/10], Step [2100/12942], Loss: 1.7411, Perplexity: 5.70385\n",
      "1561328492 - Epoch [5/10], Step [2200/12942], Loss: 1.7526, Perplexity: 5.76953\n",
      "1561328546 - Epoch [5/10], Step [2300/12942], Loss: 1.7470, Perplexity: 5.73765\n",
      "1561328599 - Epoch [5/10], Step [2400/12942], Loss: 2.0110, Perplexity: 7.47059\n",
      "1561328653 - Epoch [5/10], Step [2500/12942], Loss: 2.2778, Perplexity: 9.75569\n",
      "1561328707 - Epoch [5/10], Step [2600/12942], Loss: 1.6345, Perplexity: 5.12698\n",
      "1561328762 - Epoch [5/10], Step [2700/12942], Loss: 1.6359, Perplexity: 5.13414\n",
      "1561328816 - Epoch [5/10], Step [2800/12942], Loss: 1.5675, Perplexity: 4.79470\n",
      "1561328870 - Epoch [5/10], Step [2900/12942], Loss: 1.8267, Perplexity: 6.21351\n",
      "1561328924 - Epoch [5/10], Step [3000/12942], Loss: 1.8829, Perplexity: 6.57262\n",
      "1561328978 - Epoch [5/10], Step [3100/12942], Loss: 1.7016, Perplexity: 5.48293\n",
      "1561329032 - Epoch [5/10], Step [3200/12942], Loss: 1.8375, Perplexity: 6.28096\n",
      "1561329086 - Epoch [5/10], Step [3300/12942], Loss: 1.5698, Perplexity: 4.80570\n",
      "1561329139 - Epoch [5/10], Step [3400/12942], Loss: 1.8377, Perplexity: 6.28215\n",
      "1561329194 - Epoch [5/10], Step [3500/12942], Loss: 1.9037, Perplexity: 6.71062\n",
      "1561329247 - Epoch [5/10], Step [3600/12942], Loss: 2.1247, Perplexity: 8.37051\n",
      "1561329301 - Epoch [5/10], Step [3700/12942], Loss: 1.6402, Perplexity: 5.15622\n",
      "1561329355 - Epoch [5/10], Step [3800/12942], Loss: 1.7119, Perplexity: 5.53946\n",
      "1561329409 - Epoch [5/10], Step [3900/12942], Loss: 1.6061, Perplexity: 4.98314\n",
      "1561329463 - Epoch [5/10], Step [4000/12942], Loss: 1.7175, Perplexity: 5.57086\n",
      "1561329517 - Epoch [5/10], Step [4100/12942], Loss: 2.1232, Perplexity: 8.35792\n",
      "1561329571 - Epoch [5/10], Step [4200/12942], Loss: 1.7610, Perplexity: 5.81841\n",
      "1561329625 - Epoch [5/10], Step [4300/12942], Loss: 1.7714, Perplexity: 5.87927\n",
      "1561329679 - Epoch [5/10], Step [4400/12942], Loss: 1.7397, Perplexity: 5.69549\n",
      "1561329733 - Epoch [5/10], Step [4500/12942], Loss: 1.7844, Perplexity: 5.95601\n",
      "1561329787 - Epoch [5/10], Step [4600/12942], Loss: 1.8719, Perplexity: 6.5005\n",
      "1561329841 - Epoch [5/10], Step [4700/12942], Loss: 1.6958, Perplexity: 5.45103\n",
      "1561329895 - Epoch [5/10], Step [4800/12942], Loss: 1.8187, Perplexity: 6.16387\n",
      "1561329949 - Epoch [5/10], Step [4900/12942], Loss: 1.7785, Perplexity: 5.92084\n",
      "1561330003 - Epoch [5/10], Step [5000/12942], Loss: 1.6865, Perplexity: 5.40071\n",
      "1561330057 - Epoch [5/10], Step [5100/12942], Loss: 1.7340, Perplexity: 5.66314\n",
      "1561330111 - Epoch [5/10], Step [5200/12942], Loss: 1.9354, Perplexity: 6.92705\n",
      "1561330165 - Epoch [5/10], Step [5300/12942], Loss: 1.9287, Perplexity: 6.88071\n",
      "1561330219 - Epoch [5/10], Step [5400/12942], Loss: 1.6628, Perplexity: 5.27436\n",
      "1561330272 - Epoch [5/10], Step [5500/12942], Loss: 1.6978, Perplexity: 5.46215\n",
      "1561330327 - Epoch [5/10], Step [5600/12942], Loss: 1.7830, Perplexity: 5.94770\n",
      "1561330380 - Epoch [5/10], Step [5700/12942], Loss: 1.7420, Perplexity: 5.70885\n",
      "1561330434 - Epoch [5/10], Step [5800/12942], Loss: 1.6428, Perplexity: 5.16964\n",
      "1561330488 - Epoch [5/10], Step [5900/12942], Loss: 1.9783, Perplexity: 7.23029\n",
      "1561330543 - Epoch [5/10], Step [6000/12942], Loss: 1.8418, Perplexity: 6.30815\n",
      "1561330597 - Epoch [5/10], Step [6100/12942], Loss: 1.9017, Perplexity: 6.69720\n",
      "1561330651 - Epoch [5/10], Step [6200/12942], Loss: 1.9147, Perplexity: 6.78479\n",
      "1561330705 - Epoch [5/10], Step [6300/12942], Loss: 1.7738, Perplexity: 5.89351\n",
      "1561330759 - Epoch [5/10], Step [6400/12942], Loss: 1.7607, Perplexity: 5.81668\n",
      "1561330813 - Epoch [5/10], Step [6500/12942], Loss: 1.6961, Perplexity: 5.45278\n",
      "1561330867 - Epoch [5/10], Step [6600/12942], Loss: 1.8861, Perplexity: 6.59392\n",
      "1561330921 - Epoch [5/10], Step [6700/12942], Loss: 1.6978, Perplexity: 5.46172\n",
      "1561330975 - Epoch [5/10], Step [6800/12942], Loss: 1.8504, Perplexity: 6.36269\n",
      "1561331029 - Epoch [5/10], Step [6900/12942], Loss: 1.7735, Perplexity: 5.89121\n",
      "1561331083 - Epoch [5/10], Step [7000/12942], Loss: 1.9656, Perplexity: 7.13900\n",
      "1561331137 - Epoch [5/10], Step [7100/12942], Loss: 1.5829, Perplexity: 4.8693\n",
      "1561331191 - Epoch [5/10], Step [7200/12942], Loss: 2.2719, Perplexity: 9.69766\n",
      "1561331245 - Epoch [5/10], Step [7300/12942], Loss: 1.6944, Perplexity: 5.44340\n",
      "1561331299 - Epoch [5/10], Step [7400/12942], Loss: 2.0755, Perplexity: 7.96844\n",
      "1561331353 - Epoch [5/10], Step [7500/12942], Loss: 1.6147, Perplexity: 5.02626\n",
      "1561331407 - Epoch [5/10], Step [7600/12942], Loss: 1.7295, Perplexity: 5.63776\n",
      "1561331461 - Epoch [5/10], Step [7700/12942], Loss: 1.7672, Perplexity: 5.85475\n",
      "1561331516 - Epoch [5/10], Step [7800/12942], Loss: 1.7905, Perplexity: 5.99237\n",
      "1561331570 - Epoch [5/10], Step [7900/12942], Loss: 1.7375, Perplexity: 5.68293\n",
      "1561331624 - Epoch [5/10], Step [8000/12942], Loss: 1.6895, Perplexity: 5.41689\n",
      "1561331678 - Epoch [5/10], Step [8100/12942], Loss: 1.7326, Perplexity: 5.65518\n",
      "1561331732 - Epoch [5/10], Step [8200/12942], Loss: 1.7698, Perplexity: 5.86943\n",
      "1561331786 - Epoch [5/10], Step [8300/12942], Loss: 1.5949, Perplexity: 4.92804\n",
      "1561331840 - Epoch [5/10], Step [8400/12942], Loss: 1.8365, Perplexity: 6.27451\n",
      "1561331893 - Epoch [5/10], Step [8500/12942], Loss: 2.6151, Perplexity: 13.6690\n",
      "1561331947 - Epoch [5/10], Step [8600/12942], Loss: 1.6692, Perplexity: 5.30798\n",
      "1561332001 - Epoch [5/10], Step [8700/12942], Loss: 1.6622, Perplexity: 5.27095\n",
      "1561332056 - Epoch [5/10], Step [8800/12942], Loss: 2.2231, Perplexity: 9.23595\n",
      "1561332110 - Epoch [5/10], Step [8900/12942], Loss: 1.7203, Perplexity: 5.58640\n",
      "1561332164 - Epoch [5/10], Step [9000/12942], Loss: 1.9167, Perplexity: 6.79871\n",
      "1561332219 - Epoch [5/10], Step [9100/12942], Loss: 1.7779, Perplexity: 5.91728\n",
      "1561332273 - Epoch [5/10], Step [9200/12942], Loss: 2.0478, Perplexity: 7.75073\n",
      "1561332327 - Epoch [5/10], Step [9300/12942], Loss: 1.5167, Perplexity: 4.55748\n",
      "1561332381 - Epoch [5/10], Step [9400/12942], Loss: 2.2970, Perplexity: 9.94386\n",
      "1561332435 - Epoch [5/10], Step [9500/12942], Loss: 1.7878, Perplexity: 5.97604\n",
      "1561332489 - Epoch [5/10], Step [9600/12942], Loss: 1.6140, Perplexity: 5.02287\n",
      "1561332543 - Epoch [5/10], Step [9700/12942], Loss: 1.8349, Perplexity: 6.26431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561332597 - Epoch [5/10], Step [9800/12942], Loss: 2.3152, Perplexity: 10.1271\n",
      "1561332651 - Epoch [5/10], Step [9900/12942], Loss: 1.9475, Perplexity: 7.01142\n",
      "1561332705 - Epoch [5/10], Step [10000/12942], Loss: 1.8833, Perplexity: 6.5753\n",
      "1561332759 - Epoch [5/10], Step [10100/12942], Loss: 1.7401, Perplexity: 5.69789\n",
      "1561332813 - Epoch [5/10], Step [10200/12942], Loss: 2.0949, Perplexity: 8.12506\n",
      "1561332867 - Epoch [5/10], Step [10300/12942], Loss: 1.8224, Perplexity: 6.18668\n",
      "1561332921 - Epoch [5/10], Step [10400/12942], Loss: 1.7667, Perplexity: 5.85132\n",
      "1561332976 - Epoch [5/10], Step [10500/12942], Loss: 1.8544, Perplexity: 6.38763\n",
      "1561333030 - Epoch [5/10], Step [10600/12942], Loss: 1.7259, Perplexity: 5.61765\n",
      "1561333084 - Epoch [5/10], Step [10700/12942], Loss: 1.5859, Perplexity: 4.88364\n",
      "1561333137 - Epoch [5/10], Step [10800/12942], Loss: 1.8391, Perplexity: 6.29112\n",
      "1561333191 - Epoch [5/10], Step [10900/12942], Loss: 1.7447, Perplexity: 5.72424\n",
      "1561333245 - Epoch [5/10], Step [11000/12942], Loss: 1.9796, Perplexity: 7.23986\n",
      "1561333300 - Epoch [5/10], Step [11100/12942], Loss: 1.6529, Perplexity: 5.22187\n",
      "1561333354 - Epoch [5/10], Step [11200/12942], Loss: 1.9263, Perplexity: 6.86389\n",
      "1561333408 - Epoch [5/10], Step [11300/12942], Loss: 1.6776, Perplexity: 5.35255\n",
      "1561333462 - Epoch [5/10], Step [11400/12942], Loss: 1.9346, Perplexity: 6.92124\n",
      "1561333516 - Epoch [5/10], Step [11500/12942], Loss: 1.8955, Perplexity: 6.65585\n",
      "1561333570 - Epoch [5/10], Step [11600/12942], Loss: 1.7247, Perplexity: 5.61098\n",
      "1561333625 - Epoch [5/10], Step [11700/12942], Loss: 1.8882, Perplexity: 6.60769\n",
      "1561333678 - Epoch [5/10], Step [11800/12942], Loss: 1.7783, Perplexity: 5.92000\n",
      "1561333732 - Epoch [5/10], Step [11900/12942], Loss: 1.8392, Perplexity: 6.29164\n",
      "1561333787 - Epoch [5/10], Step [12000/12942], Loss: 1.6656, Perplexity: 5.28900\n",
      "1561333841 - Epoch [5/10], Step [12100/12942], Loss: 1.8584, Perplexity: 6.41339\n",
      "1561333895 - Epoch [5/10], Step [12200/12942], Loss: 2.0837, Perplexity: 8.0344\n",
      "1561333948 - Epoch [5/10], Step [12300/12942], Loss: 1.7495, Perplexity: 5.75195\n",
      "1561334003 - Epoch [5/10], Step [12400/12942], Loss: 1.6421, Perplexity: 5.16625\n",
      "1561334057 - Epoch [5/10], Step [12500/12942], Loss: 1.8092, Perplexity: 6.10548\n",
      "1561334111 - Epoch [5/10], Step [12600/12942], Loss: 1.7291, Perplexity: 5.63530\n",
      "1561334165 - Epoch [5/10], Step [12700/12942], Loss: 1.6008, Perplexity: 4.95690\n",
      "1561334350 - Epoch [6/10], Step [100/12942], Loss: 1.8834, Perplexity: 6.576061\n",
      "1561334404 - Epoch [6/10], Step [200/12942], Loss: 2.1991, Perplexity: 9.0171\n",
      "1561334459 - Epoch [6/10], Step [300/12942], Loss: 1.6918, Perplexity: 5.42904\n",
      "1561334513 - Epoch [6/10], Step [400/12942], Loss: 1.7848, Perplexity: 5.95850\n",
      "1561334568 - Epoch [6/10], Step [500/12942], Loss: 1.5529, Perplexity: 4.72507\n",
      "1561334622 - Epoch [6/10], Step [600/12942], Loss: 1.9475, Perplexity: 7.01122\n",
      "1561334676 - Epoch [6/10], Step [700/12942], Loss: 1.6437, Perplexity: 5.17414\n",
      "1561334730 - Epoch [6/10], Step [800/12942], Loss: 1.7764, Perplexity: 5.90879\n",
      "1561334784 - Epoch [6/10], Step [900/12942], Loss: 1.9326, Perplexity: 6.90721\n",
      "1561334838 - Epoch [6/10], Step [1000/12942], Loss: 1.8192, Perplexity: 6.1672\n",
      "1561334892 - Epoch [6/10], Step [1100/12942], Loss: 2.0439, Perplexity: 7.72056\n",
      "1561334946 - Epoch [6/10], Step [1200/12942], Loss: 1.8927, Perplexity: 6.63754\n",
      "1561335000 - Epoch [6/10], Step [1300/12942], Loss: 1.8818, Perplexity: 6.56500\n",
      "1561335054 - Epoch [6/10], Step [1400/12942], Loss: 1.8633, Perplexity: 6.44495\n",
      "1561335107 - Epoch [6/10], Step [1500/12942], Loss: 1.8260, Perplexity: 6.20876\n",
      "1561335162 - Epoch [6/10], Step [1600/12942], Loss: 2.2562, Perplexity: 9.54699\n",
      "1561335216 - Epoch [6/10], Step [1700/12942], Loss: 1.7040, Perplexity: 5.49570\n",
      "1561335270 - Epoch [6/10], Step [1800/12942], Loss: 1.7627, Perplexity: 5.828086\n",
      "1561335323 - Epoch [6/10], Step [1900/12942], Loss: 1.8096, Perplexity: 6.10824\n",
      "1561335377 - Epoch [6/10], Step [2000/12942], Loss: 1.7391, Perplexity: 5.69226\n",
      "1561335431 - Epoch [6/10], Step [2100/12942], Loss: 1.9627, Perplexity: 7.11821\n",
      "1561335485 - Epoch [6/10], Step [2200/12942], Loss: 2.3220, Perplexity: 10.1960\n",
      "1561335539 - Epoch [6/10], Step [2300/12942], Loss: 1.7551, Perplexity: 5.7842\n",
      "1561335593 - Epoch [6/10], Step [2400/12942], Loss: 1.9052, Perplexity: 6.72102\n",
      "1561335647 - Epoch [6/10], Step [2500/12942], Loss: 1.7509, Perplexity: 5.75953\n",
      "1561335702 - Epoch [6/10], Step [2600/12942], Loss: 1.8188, Perplexity: 6.16472\n",
      "1561335755 - Epoch [6/10], Step [2700/12942], Loss: 1.5068, Perplexity: 4.51255\n",
      "1561335809 - Epoch [6/10], Step [2800/12942], Loss: 1.8417, Perplexity: 6.30748\n",
      "1561335864 - Epoch [6/10], Step [2900/12942], Loss: 1.7670, Perplexity: 5.85311\n",
      "1561335902 - Epoch [6/10], Step [2972/12942], Loss: 1.7390, Perplexity: 5.69149"
=======
      "Epoch [1/10], Step [100/12942], Loss: 4.4091, Perplexity: 82.1931\n",
      "Epoch [1/10], Step [200/12942], Loss: 3.7611, Perplexity: 42.9942\n",
      "Epoch [1/10], Step [300/12942], Loss: 3.7205, Perplexity: 41.28469\n",
      "Epoch [1/10], Step [400/12942], Loss: 3.3173, Perplexity: 27.5852\n",
      "Epoch [1/10], Step [500/12942], Loss: 3.1490, Perplexity: 23.3127\n",
      "Epoch [1/10], Step [600/12942], Loss: 3.0183, Perplexity: 20.4559\n",
      "Epoch [1/10], Step [700/12942], Loss: 3.5464, Perplexity: 34.6896\n",
      "Epoch [1/10], Step [800/12942], Loss: 2.9442, Perplexity: 18.9955\n",
      "Epoch [1/10], Step [900/12942], Loss: 3.2777, Perplexity: 26.5145\n",
      "Epoch [1/10], Step [1000/12942], Loss: 2.9845, Perplexity: 19.7764\n",
      "Epoch [1/10], Step [1100/12942], Loss: 2.8793, Perplexity: 17.8014\n",
      "Epoch [1/10], Step [1200/12942], Loss: 2.9424, Perplexity: 18.9604\n",
      "Epoch [1/10], Step [1300/12942], Loss: 2.8813, Perplexity: 17.8376\n",
      "Epoch [1/10], Step [1400/12942], Loss: 2.7193, Perplexity: 15.1692\n",
      "Epoch [1/10], Step [1600/12942], Loss: 2.4754, Perplexity: 11.8869\n",
      "Epoch [1/10], Step [1700/12942], Loss: 2.7309, Perplexity: 15.3474\n",
      "Epoch [1/10], Step [1800/12942], Loss: 3.1985, Perplexity: 24.4969\n",
      "Epoch [1/10], Step [1900/12942], Loss: 2.9064, Perplexity: 18.2906\n",
      "Epoch [1/10], Step [2000/12942], Loss: 2.4979, Perplexity: 12.1573\n",
      "Epoch [1/10], Step [2100/12942], Loss: 2.4139, Perplexity: 11.1770\n",
      "Epoch [1/10], Step [2200/12942], Loss: 2.6095, Perplexity: 13.5927\n",
      "Epoch [1/10], Step [2300/12942], Loss: 2.5143, Perplexity: 12.3577\n",
      "Epoch [1/10], Step [2400/12942], Loss: 2.6403, Perplexity: 14.0175\n",
      "Epoch [1/10], Step [2500/12942], Loss: 2.7446, Perplexity: 15.5578\n",
      "Epoch [1/10], Step [2600/12942], Loss: 2.7131, Perplexity: 15.0761\n",
      "Epoch [1/10], Step [2700/12942], Loss: 2.7508, Perplexity: 15.6552\n",
      "Epoch [1/10], Step [2800/12942], Loss: 2.6869, Perplexity: 14.6866\n",
      "Epoch [1/10], Step [2900/12942], Loss: 2.4525, Perplexity: 11.6179\n",
      "Epoch [1/10], Step [3000/12942], Loss: 2.7469, Perplexity: 15.5947\n",
      "Epoch [1/10], Step [3100/12942], Loss: 2.5513, Perplexity: 12.8233\n",
      "Epoch [1/10], Step [3200/12942], Loss: 2.5192, Perplexity: 12.4181\n",
      "Epoch [1/10], Step [3300/12942], Loss: 2.6198, Perplexity: 13.7336\n",
      "Epoch [1/10], Step [3400/12942], Loss: 2.5207, Perplexity: 12.4375\n",
      "Epoch [1/10], Step [3500/12942], Loss: 2.6827, Perplexity: 14.6243\n",
      "Epoch [1/10], Step [3600/12942], Loss: 2.5339, Perplexity: 12.6029\n",
      "Epoch [1/10], Step [3700/12942], Loss: 2.2948, Perplexity: 9.92232\n",
      "Epoch [1/10], Step [3800/12942], Loss: 2.5481, Perplexity: 12.7832\n",
      "Epoch [1/10], Step [3900/12942], Loss: 2.0022, Perplexity: 7.40503\n",
      "Epoch [1/10], Step [4000/12942], Loss: 2.3047, Perplexity: 10.0210\n",
      "Epoch [1/10], Step [4100/12942], Loss: 2.1376, Perplexity: 8.47912\n",
      "Epoch [1/10], Step [4200/12942], Loss: 2.8571, Perplexity: 17.4112\n",
      "Epoch [1/10], Step [4300/12942], Loss: 2.0647, Perplexity: 7.88312\n",
      "Epoch [1/10], Step [4400/12942], Loss: 2.1934, Perplexity: 8.96526\n",
      "Epoch [1/10], Step [4500/12942], Loss: 2.3994, Perplexity: 11.0167\n",
      "Epoch [1/10], Step [4551/12942], Loss: 2.5109, Perplexity: 12.3161"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561339860 - Epoch [6/10], Step [10300/12942], Loss: 2.8333, Perplexity: 17.0023\n",
      "1561339914 - Epoch [6/10], Step [10400/12942], Loss: 1.7880, Perplexity: 5.97775\n",
      "1561339969 - Epoch [6/10], Step [10500/12942], Loss: 1.4516, Perplexity: 4.26989\n",
      "1561340023 - Epoch [6/10], Step [10600/12942], Loss: 1.8076, Perplexity: 6.09605\n",
      "1561340077 - Epoch [6/10], Step [10700/12942], Loss: 2.1466, Perplexity: 8.55583\n",
      "1561340131 - Epoch [6/10], Step [10800/12942], Loss: 1.7156, Perplexity: 5.55998\n",
      "1561340185 - Epoch [6/10], Step [10900/12942], Loss: 2.0078, Perplexity: 7.44696\n",
      "1561340239 - Epoch [6/10], Step [11000/12942], Loss: 1.9251, Perplexity: 6.855693\n",
      "1561340293 - Epoch [6/10], Step [11100/12942], Loss: 2.0676, Perplexity: 7.90619\n",
      "1561340347 - Epoch [6/10], Step [11200/12942], Loss: 1.6991, Perplexity: 5.46929\n",
      "1561340401 - Epoch [6/10], Step [11300/12942], Loss: 1.7934, Perplexity: 6.00991\n",
      "1561340455 - Epoch [6/10], Step [11400/12942], Loss: 1.7715, Perplexity: 5.8797\n",
      "1561340509 - Epoch [6/10], Step [11500/12942], Loss: 1.7322, Perplexity: 5.65292\n",
      "1561340563 - Epoch [6/10], Step [11600/12942], Loss: 1.6640, Perplexity: 5.28056\n",
      "1561340617 - Epoch [6/10], Step [11700/12942], Loss: 1.8433, Perplexity: 6.31735\n",
      "1561340671 - Epoch [6/10], Step [11800/12942], Loss: 1.9322, Perplexity: 6.90448\n",
      "1561340724 - Epoch [6/10], Step [11900/12942], Loss: 1.7562, Perplexity: 5.79027\n",
      "1561340778 - Epoch [6/10], Step [12000/12942], Loss: 1.6651, Perplexity: 5.28648\n",
      "1561340832 - Epoch [6/10], Step [12100/12942], Loss: 1.8162, Perplexity: 6.14856\n",
      "1561340886 - Epoch [6/10], Step [12200/12942], Loss: 1.7514, Perplexity: 5.76290\n",
      "1561340940 - Epoch [6/10], Step [12300/12942], Loss: 1.8283, Perplexity: 6.22307\n",
      "1561340994 - Epoch [6/10], Step [12400/12942], Loss: 1.9372, Perplexity: 6.93966\n",
      "1561341048 - Epoch [6/10], Step [12500/12942], Loss: 1.5348, Perplexity: 4.64023\n",
      "1561341104 - Epoch [6/10], Step [12600/12942], Loss: 1.9134, Perplexity: 6.77641\n",
      "1561341157 - Epoch [6/10], Step [12700/12942], Loss: 2.0660, Perplexity: 7.89359\n",
      "1561341211 - Epoch [6/10], Step [12800/12942], Loss: 2.0023, Perplexity: 7.40587\n",
      "1561341265 - Epoch [6/10], Step [12900/12942], Loss: 2.0857, Perplexity: 8.05044\n",
      "1561341342 - Epoch [7/10], Step [100/12942], Loss: 1.4960, Perplexity: 4.4640311\n",
      "1561341396 - Epoch [7/10], Step [200/12942], Loss: 1.9171, Perplexity: 6.80130\n",
      "1561341444 - Epoch [7/10], Step [288/12942], Loss: 1.7510, Perplexity: 5.76021"
=======
      "Epoch [1/10], Step [6600/12942], Loss: 2.2700, Perplexity: 9.67942\n",
      "Epoch [1/10], Step [6700/12942], Loss: 2.3717, Perplexity: 10.7152\n",
      "Epoch [1/10], Step [6800/12942], Loss: 2.1501, Perplexity: 8.58552\n",
      "Epoch [1/10], Step [6900/12942], Loss: 2.1324, Perplexity: 8.43520\n",
      "Epoch [1/10], Step [7000/12942], Loss: 2.0584, Perplexity: 7.83330\n",
      "Epoch [1/10], Step [7100/12942], Loss: 2.4558, Perplexity: 11.6553\n",
      "Epoch [1/10], Step [7200/12942], Loss: 2.1563, Perplexity: 8.63957\n",
      "Epoch [1/10], Step [7300/12942], Loss: 2.2473, Perplexity: 9.46236\n",
      "Epoch [1/10], Step [7400/12942], Loss: 2.4605, Perplexity: 11.7102\n",
      "Epoch [1/10], Step [7500/12942], Loss: 2.0349, Perplexity: 7.65131\n",
      "Epoch [1/10], Step [7600/12942], Loss: 2.0097, Perplexity: 7.46089\n",
      "Epoch [1/10], Step [7700/12942], Loss: 2.9015, Perplexity: 18.2022\n",
      "Epoch [1/10], Step [7800/12942], Loss: 1.9876, Perplexity: 7.29797\n",
      "Epoch [1/10], Step [7900/12942], Loss: 2.1604, Perplexity: 8.67426\n",
      "Epoch [1/10], Step [8000/12942], Loss: 2.2094, Perplexity: 9.11039\n",
      "Epoch [1/10], Step [8100/12942], Loss: 2.3235, Perplexity: 10.2118\n",
      "Epoch [1/10], Step [8200/12942], Loss: 2.0187, Perplexity: 7.52831\n",
      "Epoch [1/10], Step [8300/12942], Loss: 4.0099, Perplexity: 55.1414\n",
      "Epoch [1/10], Step [8400/12942], Loss: 2.1360, Perplexity: 8.46570\n",
      "Epoch [1/10], Step [8500/12942], Loss: 2.1898, Perplexity: 8.93354\n",
      "Epoch [1/10], Step [8600/12942], Loss: 1.8451, Perplexity: 6.32865\n",
      "Epoch [1/10], Step [8700/12942], Loss: 2.3742, Perplexity: 10.7426\n",
      "Epoch [1/10], Step [8800/12942], Loss: 2.2126, Perplexity: 9.13968\n",
      "Epoch [1/10], Step [8900/12942], Loss: 2.1625, Perplexity: 8.69253\n",
      "Epoch [1/10], Step [9000/12942], Loss: 2.5458, Perplexity: 12.7534\n",
      "Epoch [1/10], Step [9100/12942], Loss: 1.8881, Perplexity: 6.60704\n",
      "Epoch [1/10], Step [9200/12942], Loss: 2.3324, Perplexity: 10.3031\n",
      "Epoch [1/10], Step [9300/12942], Loss: 2.1034, Perplexity: 8.19375\n",
      "Epoch [1/10], Step [9400/12942], Loss: 2.3794, Perplexity: 10.7984\n",
      "Epoch [1/10], Step [9500/12942], Loss: 2.0738, Perplexity: 7.955034"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561345402 - Epoch [7/10], Step [7600/12942], Loss: 1.8118, Perplexity: 6.12173\n",
      "1561345455 - Epoch [7/10], Step [7700/12942], Loss: 1.9782, Perplexity: 7.22948\n",
      "1561345509 - Epoch [7/10], Step [7800/12942], Loss: 1.7559, Perplexity: 5.78852\n",
      "1561345564 - Epoch [7/10], Step [7900/12942], Loss: 1.7579, Perplexity: 5.80046\n",
      "1561345618 - Epoch [7/10], Step [8000/12942], Loss: 1.8924, Perplexity: 6.63550\n",
      "1561345672 - Epoch [7/10], Step [8100/12942], Loss: 1.7827, Perplexity: 5.94583\n",
      "1561345726 - Epoch [7/10], Step [8200/12942], Loss: 1.6911, Perplexity: 5.42560\n",
      "1561345780 - Epoch [7/10], Step [8300/12942], Loss: 1.6873, Perplexity: 5.40488\n",
      "1561345834 - Epoch [7/10], Step [8400/12942], Loss: 1.7528, Perplexity: 5.77102\n",
      "1561345889 - Epoch [7/10], Step [8500/12942], Loss: 1.9514, Perplexity: 7.03831\n",
      "1561345944 - Epoch [7/10], Step [8600/12942], Loss: 1.7437, Perplexity: 5.71855\n",
      "1561345997 - Epoch [7/10], Step [8700/12942], Loss: 1.8096, Perplexity: 6.10800\n",
      "1561346051 - Epoch [7/10], Step [8800/12942], Loss: 1.9996, Perplexity: 7.38616\n",
      "1561346106 - Epoch [7/10], Step [8900/12942], Loss: 1.8142, Perplexity: 6.13610\n",
      "1561346160 - Epoch [7/10], Step [9000/12942], Loss: 1.8170, Perplexity: 6.15344\n",
      "1561346214 - Epoch [7/10], Step [9100/12942], Loss: 1.6110, Perplexity: 5.00802\n",
      "1561346269 - Epoch [7/10], Step [9200/12942], Loss: 1.6592, Perplexity: 5.25508\n",
      "1561346322 - Epoch [7/10], Step [9300/12942], Loss: 1.7788, Perplexity: 5.92308\n",
      "1561346376 - Epoch [7/10], Step [9400/12942], Loss: 2.0561, Perplexity: 7.81573\n",
      "1561346430 - Epoch [7/10], Step [9500/12942], Loss: 1.7474, Perplexity: 5.73954\n",
      "1561346485 - Epoch [7/10], Step [9600/12942], Loss: 1.7749, Perplexity: 5.8995\n",
      "1561346539 - Epoch [7/10], Step [9700/12942], Loss: 1.8916, Perplexity: 6.62983\n",
      "1561346593 - Epoch [7/10], Step [9800/12942], Loss: 1.6214, Perplexity: 5.06039\n",
      "1561346647 - Epoch [7/10], Step [9900/12942], Loss: 2.0402, Perplexity: 7.69187\n",
      "1561346701 - Epoch [7/10], Step [10000/12942], Loss: 1.7618, Perplexity: 5.8227\n",
      "1561346755 - Epoch [7/10], Step [10100/12942], Loss: 1.7399, Perplexity: 5.69672\n",
      "1561346809 - Epoch [7/10], Step [10200/12942], Loss: 1.7448, Perplexity: 5.72452\n",
      "1561346864 - Epoch [7/10], Step [10300/12942], Loss: 1.7412, Perplexity: 5.70397\n",
      "1561346918 - Epoch [7/10], Step [10400/12942], Loss: 2.2953, Perplexity: 9.92716\n",
      "1561346972 - Epoch [7/10], Step [10500/12942], Loss: 2.4335, Perplexity: 11.3990\n",
      "1561347004 - Epoch [7/10], Step [10559/12942], Loss: 1.8057, Perplexity: 6.08449"
=======
      "Epoch [1/10], Step [10700/12942], Loss: 2.3163, Perplexity: 10.1382\n",
      "Epoch [1/10], Step [10800/12942], Loss: 1.9977, Perplexity: 7.37238\n",
      "Epoch [1/10], Step [10900/12942], Loss: 2.3389, Perplexity: 10.3699\n",
      "Epoch [1/10], Step [11000/12942], Loss: 2.0415, Perplexity: 7.70217\n",
      "Epoch [1/10], Step [11100/12942], Loss: 2.1721, Perplexity: 8.77664\n",
      "Epoch [1/10], Step [11200/12942], Loss: 1.9064, Perplexity: 6.72900\n",
      "Epoch [1/10], Step [11300/12942], Loss: 2.3553, Perplexity: 10.5409\n",
      "Epoch [1/10], Step [11400/12942], Loss: 3.1134, Perplexity: 22.4963\n",
      "Epoch [1/10], Step [11500/12942], Loss: 2.1806, Perplexity: 8.85158\n",
      "Epoch [1/10], Step [11600/12942], Loss: 2.1237, Perplexity: 8.36245\n",
      "Epoch [1/10], Step [11700/12942], Loss: 2.0054, Perplexity: 7.42940\n",
      "Epoch [1/10], Step [11800/12942], Loss: 1.9689, Perplexity: 7.16270\n",
      "Epoch [1/10], Step [11900/12942], Loss: 2.2295, Perplexity: 9.29495\n",
      "Epoch [1/10], Step [12000/12942], Loss: 2.3271, Perplexity: 10.2486\n",
      "Epoch [1/10], Step [12100/12942], Loss: 2.3458, Perplexity: 10.4412\n",
      "Epoch [1/10], Step [12200/12942], Loss: 2.1284, Perplexity: 8.40158\n",
      "Epoch [1/10], Step [12300/12942], Loss: 2.2504, Perplexity: 9.49149\n",
      "Epoch [1/10], Step [12400/12942], Loss: 3.0648, Perplexity: 21.4306\n",
      "Epoch [1/10], Step [12500/12942], Loss: 2.2073, Perplexity: 9.09154\n",
      "Epoch [1/10], Step [12600/12942], Loss: 2.4475, Perplexity: 11.5589\n",
      "Epoch [1/10], Step [12700/12942], Loss: 2.1158, Perplexity: 8.29624\n",
      "Epoch [1/10], Step [12800/12942], Loss: 2.0804, Perplexity: 8.00740\n",
      "Epoch [1/10], Step [12900/12942], Loss: 2.1070, Perplexity: 8.22339\n",
      "Epoch [2/10], Step [100/12942], Loss: 1.9028, Perplexity: 6.7049813\n",
      "Epoch [2/10], Step [200/12942], Loss: 1.8523, Perplexity: 6.37449\n",
      "Epoch [2/10], Step [300/12942], Loss: 1.8895, Perplexity: 6.61602\n",
      "Epoch [2/10], Step [400/12942], Loss: 2.2716, Perplexity: 9.69470\n",
      "Epoch [2/10], Step [500/12942], Loss: 2.1937, Perplexity: 8.96823\n",
      "Epoch [2/10], Step [600/12942], Loss: 2.0904, Perplexity: 8.08788\n",
      "Epoch [2/10], Step [800/12942], Loss: 2.0801, Perplexity: 8.00499\n",
      "Epoch [2/10], Step [900/12942], Loss: 2.2838, Perplexity: 9.81367\n",
      "Epoch [2/10], Step [1000/12942], Loss: 1.9681, Perplexity: 7.1570\n",
      "Epoch [2/10], Step [1100/12942], Loss: 2.1526, Perplexity: 8.60745\n",
      "Epoch [2/10], Step [1200/12942], Loss: 2.0698, Perplexity: 7.92292\n",
      "Epoch [2/10], Step [1300/12942], Loss: 2.1198, Perplexity: 8.32910\n",
      "Epoch [2/10], Step [1400/12942], Loss: 2.0099, Perplexity: 7.46251\n",
      "Epoch [2/10], Step [1500/12942], Loss: 2.0618, Perplexity: 7.86042\n",
      "Epoch [2/10], Step [1600/12942], Loss: 2.1167, Perplexity: 8.30387\n",
      "Epoch [2/10], Step [1700/12942], Loss: 2.1217, Perplexity: 8.34538\n",
      "Epoch [2/10], Step [1800/12942], Loss: 1.7750, Perplexity: 5.90042\n",
      "Epoch [2/10], Step [1900/12942], Loss: 2.3220, Perplexity: 10.1965\n",
      "Epoch [2/10], Step [2000/12942], Loss: 2.4240, Perplexity: 11.2909\n",
      "Epoch [2/10], Step [2100/12942], Loss: 2.1268, Perplexity: 8.38845\n",
      "Epoch [2/10], Step [2200/12942], Loss: 2.4098, Perplexity: 11.1314\n",
      "Epoch [2/10], Step [2300/12942], Loss: 1.9138, Perplexity: 6.77913\n",
      "Epoch [2/10], Step [2400/12942], Loss: 1.9883, Perplexity: 7.30305\n",
      "Epoch [2/10], Step [2500/12942], Loss: 2.1162, Perplexity: 8.29963\n",
      "Epoch [2/10], Step [2600/12942], Loss: 2.2770, Perplexity: 9.74750\n",
      "Epoch [2/10], Step [2700/12942], Loss: 2.1506, Perplexity: 8.58966\n",
      "Epoch [2/10], Step [2800/12942], Loss: 2.0149, Perplexity: 7.50039\n",
      "Epoch [2/10], Step [2900/12942], Loss: 2.3012, Perplexity: 9.98660\n",
      "Epoch [2/10], Step [3000/12942], Loss: 1.9026, Perplexity: 6.70343\n",
      "Epoch [2/10], Step [3100/12942], Loss: 1.7982, Perplexity: 6.03907\n",
      "Epoch [2/10], Step [3200/12942], Loss: 2.0544, Perplexity: 7.80215\n",
      "Epoch [2/10], Step [3300/12942], Loss: 2.0619, Perplexity: 7.86059\n",
      "Epoch [2/10], Step [3400/12942], Loss: 2.1779, Perplexity: 8.82754\n",
      "Epoch [2/10], Step [3500/12942], Loss: 3.3472, Perplexity: 28.4234\n",
      "Epoch [2/10], Step [3600/12942], Loss: 2.0644, Perplexity: 7.88033\n",
      "Epoch [2/10], Step [3700/12942], Loss: 2.2439, Perplexity: 9.42974\n",
      "Epoch [2/10], Step [3708/12942], Loss: 2.4082, Perplexity: 11.1144"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561350941 - Epoch [8/10], Step [4900/12942], Loss: 1.9601, Perplexity: 7.10046\n",
      "1561350995 - Epoch [8/10], Step [5000/12942], Loss: 1.7855, Perplexity: 5.96282\n",
      "1561351049 - Epoch [8/10], Step [5100/12942], Loss: 2.0594, Perplexity: 7.84148\n",
      "1561351103 - Epoch [8/10], Step [5200/12942], Loss: 1.6830, Perplexity: 5.38192\n",
      "1561351157 - Epoch [8/10], Step [5300/12942], Loss: 1.7942, Perplexity: 6.01452\n",
      "1561351210 - Epoch [8/10], Step [5400/12942], Loss: 1.9200, Perplexity: 6.82094\n",
      "1561351264 - Epoch [8/10], Step [5500/12942], Loss: 1.9642, Perplexity: 7.12917\n",
      "1561351318 - Epoch [8/10], Step [5600/12942], Loss: 1.6909, Perplexity: 5.4245\n",
      "1561351372 - Epoch [8/10], Step [5700/12942], Loss: 1.6511, Perplexity: 5.21286\n",
      "1561351426 - Epoch [8/10], Step [5800/12942], Loss: 1.5798, Perplexity: 4.85414\n",
      "1561351480 - Epoch [8/10], Step [5900/12942], Loss: 1.6986, Perplexity: 5.466521\n",
      "1561351535 - Epoch [8/10], Step [6000/12942], Loss: 2.0726, Perplexity: 7.94585\n",
      "1561351588 - Epoch [8/10], Step [6100/12942], Loss: 1.9324, Perplexity: 6.90648\n",
      "1561351643 - Epoch [8/10], Step [6200/12942], Loss: 1.9146, Perplexity: 6.78452\n",
      "1561351697 - Epoch [8/10], Step [6300/12942], Loss: 1.8385, Perplexity: 6.28735\n",
      "1561351750 - Epoch [8/10], Step [6400/12942], Loss: 1.8808, Perplexity: 6.55908\n",
      "1561351805 - Epoch [8/10], Step [6500/12942], Loss: 1.8279, Perplexity: 6.22078\n",
      "1561351859 - Epoch [8/10], Step [6600/12942], Loss: 1.7991, Perplexity: 6.04400\n",
      "1561351913 - Epoch [8/10], Step [6700/12942], Loss: 1.5859, Perplexity: 4.88379\n",
      "1561351966 - Epoch [8/10], Step [6800/12942], Loss: 2.2145, Perplexity: 9.15689\n",
      "1561352020 - Epoch [8/10], Step [6900/12942], Loss: 1.6380, Perplexity: 5.14474\n",
      "1561352074 - Epoch [8/10], Step [7000/12942], Loss: 1.5393, Perplexity: 4.66155\n",
      "1561352128 - Epoch [8/10], Step [7100/12942], Loss: 1.9925, Perplexity: 7.33419\n",
      "1561352182 - Epoch [8/10], Step [7200/12942], Loss: 1.7695, Perplexity: 5.86796\n",
      "1561352237 - Epoch [8/10], Step [7300/12942], Loss: 2.0991, Perplexity: 8.15879\n",
      "1561352291 - Epoch [8/10], Step [7400/12942], Loss: 1.7908, Perplexity: 5.99457\n",
      "1561352345 - Epoch [8/10], Step [7500/12942], Loss: 1.6812, Perplexity: 5.37199\n",
      "1561352398 - Epoch [8/10], Step [7600/12942], Loss: 1.6287, Perplexity: 5.09743\n",
      "1561352452 - Epoch [8/10], Step [7700/12942], Loss: 2.0088, Perplexity: 7.45473\n",
      "1561352506 - Epoch [8/10], Step [7800/12942], Loss: 1.6972, Perplexity: 5.45858\n",
      "1561352519 - Epoch [8/10], Step [7824/12942], Loss: 2.0020, Perplexity: 7.40373"
=======
      "Epoch [2/10], Step [5800/12942], Loss: 2.2667, Perplexity: 9.64717\n",
      "Epoch [2/10], Step [5900/12942], Loss: 3.8529, Perplexity: 47.1303\n",
      "Epoch [2/10], Step [6000/12942], Loss: 2.3990, Perplexity: 11.0125\n",
      "Epoch [2/10], Step [6100/12942], Loss: 2.0276, Perplexity: 7.59583\n",
      "Epoch [2/10], Step [6200/12942], Loss: 2.0928, Perplexity: 8.10779\n",
      "Epoch [2/10], Step [6300/12942], Loss: 2.4376, Perplexity: 11.4451\n",
      "Epoch [2/10], Step [6400/12942], Loss: 2.0034, Perplexity: 7.41395\n",
      "Epoch [2/10], Step [6500/12942], Loss: 2.3856, Perplexity: 10.8658\n",
      "Epoch [2/10], Step [6600/12942], Loss: 2.1506, Perplexity: 8.59044\n",
      "Epoch [2/10], Step [6700/12942], Loss: 2.2776, Perplexity: 9.75293\n",
      "Epoch [2/10], Step [6800/12942], Loss: 2.0457, Perplexity: 7.73478\n",
      "Epoch [2/10], Step [6900/12942], Loss: 2.0393, Perplexity: 7.68524\n",
      "Epoch [2/10], Step [7000/12942], Loss: 2.2095, Perplexity: 9.11132\n",
      "Epoch [2/10], Step [7100/12942], Loss: 2.2227, Perplexity: 9.23216\n",
      "Epoch [2/10], Step [7200/12942], Loss: 2.8213, Perplexity: 16.7992\n",
      "Epoch [2/10], Step [7300/12942], Loss: 2.2139, Perplexity: 9.15155\n",
      "Epoch [2/10], Step [7400/12942], Loss: 2.0784, Perplexity: 7.99167\n",
      "Epoch [2/10], Step [7500/12942], Loss: 2.1011, Perplexity: 8.17527\n",
      "Epoch [2/10], Step [7600/12942], Loss: 2.3496, Perplexity: 10.4814\n",
      "Epoch [2/10], Step [7700/12942], Loss: 3.0326, Perplexity: 20.7506\n",
      "Epoch [2/10], Step [7800/12942], Loss: 1.8962, Perplexity: 6.66064\n",
      "Epoch [2/10], Step [7900/12942], Loss: 2.0969, Perplexity: 8.14136\n",
      "Epoch [2/10], Step [8000/12942], Loss: 2.2890, Perplexity: 9.86521\n",
      "Epoch [2/10], Step [8100/12942], Loss: 2.0084, Perplexity: 7.45147\n",
      "Epoch [2/10], Step [8200/12942], Loss: 2.0625, Perplexity: 7.86562\n",
      "Epoch [2/10], Step [8300/12942], Loss: 2.0422, Perplexity: 7.70774\n",
      "Epoch [2/10], Step [8400/12942], Loss: 2.1201, Perplexity: 8.33200\n",
      "Epoch [2/10], Step [8500/12942], Loss: 2.2431, Perplexity: 9.42259\n",
      "Epoch [2/10], Step [8600/12942], Loss: 2.4333, Perplexity: 11.3969\n",
      "Epoch [2/10], Step [8700/12942], Loss: 2.0885, Perplexity: 8.07250\n",
      "Epoch [2/10], Step [8742/12942], Loss: 2.3209, Perplexity: 10.1844"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561356263 - Epoch [9/10], Step [1800/12942], Loss: 1.9375, Perplexity: 6.94145\n",
      "1561356316 - Epoch [9/10], Step [1900/12942], Loss: 1.6746, Perplexity: 5.33659\n",
      "1561356370 - Epoch [9/10], Step [2000/12942], Loss: 1.6645, Perplexity: 5.28328\n",
      "1561356425 - Epoch [9/10], Step [2100/12942], Loss: 1.7801, Perplexity: 5.93078\n",
      "1561356479 - Epoch [9/10], Step [2200/12942], Loss: 1.7748, Perplexity: 5.899418\n",
      "1561356533 - Epoch [9/10], Step [2300/12942], Loss: 2.3198, Perplexity: 10.1737\n",
      "1561356587 - Epoch [9/10], Step [2400/12942], Loss: 1.8800, Perplexity: 6.55358\n",
      "1561356642 - Epoch [9/10], Step [2500/12942], Loss: 2.0105, Perplexity: 7.46716\n",
      "1561356696 - Epoch [9/10], Step [2600/12942], Loss: 2.3012, Perplexity: 9.98657\n",
      "1561356750 - Epoch [9/10], Step [2700/12942], Loss: 2.0851, Perplexity: 8.04521\n",
      "1561356804 - Epoch [9/10], Step [2800/12942], Loss: 1.7928, Perplexity: 6.00657\n",
      "1561356858 - Epoch [9/10], Step [2900/12942], Loss: 1.8295, Perplexity: 6.23060\n",
      "1561356912 - Epoch [9/10], Step [3000/12942], Loss: 1.8914, Perplexity: 6.62873\n",
      "1561356966 - Epoch [9/10], Step [3100/12942], Loss: 1.9872, Perplexity: 7.29494\n",
      "1561357020 - Epoch [9/10], Step [3200/12942], Loss: 1.9949, Perplexity: 7.35187\n",
      "1561357075 - Epoch [9/10], Step [3300/12942], Loss: 1.6853, Perplexity: 5.39426\n",
      "1561357128 - Epoch [9/10], Step [3400/12942], Loss: 1.7835, Perplexity: 5.95046\n",
      "1561357183 - Epoch [9/10], Step [3500/12942], Loss: 1.9690, Perplexity: 7.16355\n",
      "1561357237 - Epoch [9/10], Step [3600/12942], Loss: 1.6177, Perplexity: 5.04175\n",
      "1561357292 - Epoch [9/10], Step [3700/12942], Loss: 1.6647, Perplexity: 5.28399\n",
      "1561357347 - Epoch [9/10], Step [3800/12942], Loss: 1.9760, Perplexity: 7.21411\n",
      "1561357401 - Epoch [9/10], Step [3900/12942], Loss: 1.7647, Perplexity: 5.83984\n",
      "1561357455 - Epoch [9/10], Step [4000/12942], Loss: 1.8642, Perplexity: 6.45077\n",
      "1561357509 - Epoch [9/10], Step [4100/12942], Loss: 2.1041, Perplexity: 8.19997\n",
      "1561357564 - Epoch [9/10], Step [4200/12942], Loss: 1.7026, Perplexity: 5.48835\n",
      "1561357618 - Epoch [9/10], Step [4300/12942], Loss: 2.1533, Perplexity: 8.6131\n",
      "1561357672 - Epoch [9/10], Step [4400/12942], Loss: 1.6400, Perplexity: 5.15537\n",
      "1561357726 - Epoch [9/10], Step [4500/12942], Loss: 1.7115, Perplexity: 5.53732\n",
      "1561357781 - Epoch [9/10], Step [4600/12942], Loss: 1.7336, Perplexity: 5.66107\n",
      "1561357835 - Epoch [9/10], Step [4700/12942], Loss: 1.8388, Perplexity: 6.28931\n",
      "1561357862 - Epoch [9/10], Step [4751/12942], Loss: 1.9468, Perplexity: 7.0064"
=======
      "Epoch [2/10], Step [10500/12942], Loss: 2.2344, Perplexity: 9.34059\n",
      "Epoch [2/10], Step [10600/12942], Loss: 2.0748, Perplexity: 7.96313\n",
      "Epoch [2/10], Step [10700/12942], Loss: 2.2941, Perplexity: 9.91551\n",
      "Epoch [2/10], Step [10800/12942], Loss: 1.8470, Perplexity: 6.34088\n",
      "Epoch [2/10], Step [10900/12942], Loss: 1.9943, Perplexity: 7.34706\n",
      "Epoch [2/10], Step [11000/12942], Loss: 2.2145, Perplexity: 9.15701\n",
      "Epoch [2/10], Step [11100/12942], Loss: 2.1477, Perplexity: 8.56484\n",
      "Epoch [2/10], Step [11200/12942], Loss: 1.8643, Perplexity: 6.45137\n",
      "Epoch [2/10], Step [11300/12942], Loss: 1.8829, Perplexity: 6.57268\n",
      "Epoch [2/10], Step [11400/12942], Loss: 1.9331, Perplexity: 6.91121\n",
      "Epoch [2/10], Step [11500/12942], Loss: 2.1572, Perplexity: 8.64720\n",
      "Epoch [2/10], Step [11600/12942], Loss: 2.9279, Perplexity: 18.6891\n",
      "Epoch [2/10], Step [11700/12942], Loss: 2.1641, Perplexity: 8.70666\n",
      "Epoch [2/10], Step [11800/12942], Loss: 2.1246, Perplexity: 8.36958\n",
      "Epoch [2/10], Step [11900/12942], Loss: 1.8584, Perplexity: 6.41349\n",
      "Epoch [2/10], Step [12000/12942], Loss: 2.5125, Perplexity: 12.3357\n",
      "Epoch [2/10], Step [12100/12942], Loss: 1.9332, Perplexity: 6.91136\n",
      "Epoch [2/10], Step [12200/12942], Loss: 2.2883, Perplexity: 9.85864\n",
      "Epoch [2/10], Step [12300/12942], Loss: 2.0646, Perplexity: 7.88181\n",
      "Epoch [2/10], Step [12400/12942], Loss: 1.9703, Perplexity: 7.17252\n",
      "Epoch [2/10], Step [12500/12942], Loss: 2.0005, Perplexity: 7.39308\n",
      "Epoch [2/10], Step [12600/12942], Loss: 2.2717, Perplexity: 9.69560\n",
      "Epoch [2/10], Step [12700/12942], Loss: 1.9418, Perplexity: 6.97119\n",
      "Epoch [2/10], Step [12800/12942], Loss: 1.7644, Perplexity: 5.83831\n",
      "Epoch [2/10], Step [12900/12942], Loss: 2.3545, Perplexity: 10.5329\n",
      "Epoch [3/10], Step [100/12942], Loss: 1.9507, Perplexity: 7.0336173\n",
      "Epoch [3/10], Step [200/12942], Loss: 2.2776, Perplexity: 9.75306\n",
      "Epoch [3/10], Step [300/12942], Loss: 2.1283, Perplexity: 8.40058\n",
      "Epoch [3/10], Step [400/12942], Loss: 2.2111, Perplexity: 9.12559\n",
      "Epoch [3/10], Step [477/12942], Loss: 2.1721, Perplexity: 8.77674"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561361846 - Epoch [9/10], Step [12100/12942], Loss: 1.4776, Perplexity: 4.3824\n",
      "1561361900 - Epoch [9/10], Step [12200/12942], Loss: 1.6104, Perplexity: 5.0050\n",
      "1561361954 - Epoch [9/10], Step [12300/12942], Loss: 1.8422, Perplexity: 6.31061\n",
      "1561362008 - Epoch [9/10], Step [12400/12942], Loss: 1.8214, Perplexity: 6.18066\n",
      "1561362063 - Epoch [9/10], Step [12500/12942], Loss: 1.8401, Perplexity: 6.29719\n",
      "1561362117 - Epoch [9/10], Step [12600/12942], Loss: 1.8159, Perplexity: 6.14694\n",
      "1561362171 - Epoch [9/10], Step [12700/12942], Loss: 1.8623, Perplexity: 6.43848\n",
      "1561362225 - Epoch [9/10], Step [12800/12942], Loss: 2.0363, Perplexity: 7.66256\n",
      "1561362279 - Epoch [9/10], Step [12900/12942], Loss: 1.8764, Perplexity: 6.52981\n",
      "1561362356 - Epoch [10/10], Step [100/12942], Loss: 1.8397, Perplexity: 6.294876\n",
      "1561362410 - Epoch [10/10], Step [200/12942], Loss: 1.8346, Perplexity: 6.26254\n",
      "1561362463 - Epoch [10/10], Step [300/12942], Loss: 1.7236, Perplexity: 5.60492\n",
      "1561362517 - Epoch [10/10], Step [400/12942], Loss: 1.9669, Perplexity: 7.14838\n",
      "1561362571 - Epoch [10/10], Step [500/12942], Loss: 1.7575, Perplexity: 5.79826\n",
      "1561362625 - Epoch [10/10], Step [600/12942], Loss: 1.6038, Perplexity: 4.97217\n",
      "1561362680 - Epoch [10/10], Step [700/12942], Loss: 1.6540, Perplexity: 5.2278\n",
      "1561362734 - Epoch [10/10], Step [800/12942], Loss: 1.7572, Perplexity: 5.79606\n",
      "1561362788 - Epoch [10/10], Step [900/12942], Loss: 1.7520, Perplexity: 5.76634\n",
      "1561362843 - Epoch [10/10], Step [1000/12942], Loss: 2.3332, Perplexity: 10.3112\n",
      "1561362896 - Epoch [10/10], Step [1100/12942], Loss: 1.7714, Perplexity: 5.87906\n",
      "1561362950 - Epoch [10/10], Step [1200/12942], Loss: 1.7522, Perplexity: 5.76712\n",
      "1561363004 - Epoch [10/10], Step [1300/12942], Loss: 1.9408, Perplexity: 6.9646\n",
      "1561363058 - Epoch [10/10], Step [1400/12942], Loss: 1.7483, Perplexity: 5.74506\n",
      "1561363112 - Epoch [10/10], Step [1500/12942], Loss: 1.6458, Perplexity: 5.18545\n",
      "1561363166 - Epoch [10/10], Step [1600/12942], Loss: 1.5676, Perplexity: 4.7953\n",
      "1561363221 - Epoch [10/10], Step [1700/12942], Loss: 1.8462, Perplexity: 6.33567\n",
      "1561363275 - Epoch [10/10], Step [1800/12942], Loss: 1.9254, Perplexity: 6.85766\n",
      "1561363330 - Epoch [10/10], Step [1900/12942], Loss: 1.7726, Perplexity: 5.8864\n",
      "1561363384 - Epoch [10/10], Step [2000/12942], Loss: 1.7222, Perplexity: 5.59693\n",
      "1561363412 - Epoch [10/10], Step [2053/12942], Loss: 2.0155, Perplexity: 7.50438"
=======
      "Epoch [3/10], Step [2100/12942], Loss: 1.8856, Perplexity: 6.5900\n",
      "Epoch [3/10], Step [2200/12942], Loss: 1.9139, Perplexity: 6.77976\n",
      "Epoch [3/10], Step [2300/12942], Loss: 1.9618, Perplexity: 7.11226\n",
      "Epoch [3/10], Step [2400/12942], Loss: 2.0842, Perplexity: 8.03807\n",
      "Epoch [3/10], Step [2500/12942], Loss: 1.9554, Perplexity: 7.06653\n",
      "Epoch [3/10], Step [2600/12942], Loss: 1.8897, Perplexity: 6.61749\n",
      "Epoch [3/10], Step [2700/12942], Loss: 2.2488, Perplexity: 9.47602\n",
      "Epoch [3/10], Step [2800/12942], Loss: 1.9894, Perplexity: 7.31109\n",
      "Epoch [3/10], Step [2900/12942], Loss: 2.0185, Perplexity: 7.52716\n",
      "Epoch [3/10], Step [3000/12942], Loss: 1.7201, Perplexity: 5.58527\n",
      "Epoch [3/10], Step [3100/12942], Loss: 1.8311, Perplexity: 6.24080\n",
      "Epoch [3/10], Step [3200/12942], Loss: 1.9283, Perplexity: 6.87767\n",
      "Epoch [3/10], Step [3300/12942], Loss: 2.0942, Perplexity: 8.11930\n",
      "Epoch [3/10], Step [3400/12942], Loss: 2.1195, Perplexity: 8.32719\n",
      "Epoch [3/10], Step [3500/12942], Loss: 1.7582, Perplexity: 5.80180\n",
      "Epoch [3/10], Step [3600/12942], Loss: 2.0383, Perplexity: 7.67739\n",
      "Epoch [3/10], Step [3700/12942], Loss: 1.8774, Perplexity: 6.53624\n",
      "Epoch [3/10], Step [3800/12942], Loss: 1.9451, Perplexity: 6.99445\n",
      "Epoch [3/10], Step [3900/12942], Loss: 2.0087, Perplexity: 7.45393\n",
      "Epoch [3/10], Step [4000/12942], Loss: 2.2786, Perplexity: 9.76312\n",
      "Epoch [3/10], Step [4100/12942], Loss: 2.0240, Perplexity: 7.56857\n",
      "Epoch [3/10], Step [4200/12942], Loss: 1.7887, Perplexity: 5.98144\n",
      "Epoch [3/10], Step [4300/12942], Loss: 1.9739, Perplexity: 7.19895\n",
      "Epoch [3/10], Step [4400/12942], Loss: 2.1809, Perplexity: 8.85394\n",
      "Epoch [3/10], Step [4500/12942], Loss: 1.9768, Perplexity: 7.21930\n",
      "Epoch [3/10], Step [4600/12942], Loss: 1.6178, Perplexity: 5.04187\n",
      "Epoch [3/10], Step [4700/12942], Loss: 1.9113, Perplexity: 6.76200\n",
      "Epoch [3/10], Step [4800/12942], Loss: 2.0580, Perplexity: 7.83073\n",
      "Epoch [3/10], Step [4900/12942], Loss: 1.7206, Perplexity: 5.58788\n",
      "Epoch [3/10], Step [5000/12942], Loss: 1.7803, Perplexity: 5.93161\n",
      "Epoch [3/10], Step [5070/12942], Loss: 2.0692, Perplexity: 7.91834"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1561367114 - Epoch [10/10], Step [8900/12942], Loss: 1.5975, Perplexity: 4.9405\n",
      "1561367168 - Epoch [10/10], Step [9000/12942], Loss: 1.9653, Perplexity: 7.13680\n",
      "1561367222 - Epoch [10/10], Step [9100/12942], Loss: 1.7867, Perplexity: 5.96957\n",
      "1561367277 - Epoch [10/10], Step [9200/12942], Loss: 1.6380, Perplexity: 5.14498\n",
      "1561367330 - Epoch [10/10], Step [9300/12942], Loss: 1.7385, Perplexity: 5.68898\n",
      "1561367385 - Epoch [10/10], Step [9400/12942], Loss: 1.6544, Perplexity: 5.23004\n",
      "1561367439 - Epoch [10/10], Step [9500/12942], Loss: 1.9233, Perplexity: 6.84372\n",
      "1561367493 - Epoch [10/10], Step [9600/12942], Loss: 1.7393, Perplexity: 5.69321\n",
      "1561367547 - Epoch [10/10], Step [9700/12942], Loss: 1.5400, Perplexity: 4.66470\n",
      "1561367601 - Epoch [10/10], Step [9800/12942], Loss: 1.7277, Perplexity: 5.62752\n",
      "1561367655 - Epoch [10/10], Step [9900/12942], Loss: 1.8834, Perplexity: 6.57580\n",
      "1561367709 - Epoch [10/10], Step [10000/12942], Loss: 1.7853, Perplexity: 5.9615\n",
      "1561367763 - Epoch [10/10], Step [10100/12942], Loss: 1.8033, Perplexity: 6.06968\n",
      "1561367817 - Epoch [10/10], Step [10200/12942], Loss: 1.8717, Perplexity: 6.49959\n",
      "1561367871 - Epoch [10/10], Step [10300/12942], Loss: 1.9912, Perplexity: 7.32405\n",
      "1561367924 - Epoch [10/10], Step [10400/12942], Loss: 1.7908, Perplexity: 5.99440\n",
      "1561367978 - Epoch [10/10], Step [10500/12942], Loss: 1.6173, Perplexity: 5.03927\n",
      "1561368032 - Epoch [10/10], Step [10600/12942], Loss: 1.9002, Perplexity: 6.68735\n",
      "1561368086 - Epoch [10/10], Step [10700/12942], Loss: 1.9381, Perplexity: 6.94575\n",
      "1561368140 - Epoch [10/10], Step [10800/12942], Loss: 1.6008, Perplexity: 4.95727\n",
      "1561368195 - Epoch [10/10], Step [10900/12942], Loss: 1.7753, Perplexity: 5.90181\n",
      "1561368250 - Epoch [10/10], Step [11000/12942], Loss: 1.6202, Perplexity: 5.05419\n",
      "1561368304 - Epoch [10/10], Step [11100/12942], Loss: 1.9148, Perplexity: 6.78556\n",
      "1561368359 - Epoch [10/10], Step [11200/12942], Loss: 2.5695, Perplexity: 13.0589\n",
      "1561368414 - Epoch [10/10], Step [11300/12942], Loss: 2.8687, Perplexity: 17.6136\n",
      "1561368470 - Epoch [10/10], Step [11400/12942], Loss: 1.7650, Perplexity: 5.84156\n",
      "1561368524 - Epoch [10/10], Step [11500/12942], Loss: 1.7093, Perplexity: 5.52504\n",
      "1561368578 - Epoch [10/10], Step [11600/12942], Loss: 1.7642, Perplexity: 5.83723\n",
      "1561368632 - Epoch [10/10], Step [11700/12942], Loss: 1.7068, Perplexity: 5.51112\n",
      "1561368686 - Epoch [10/10], Step [11800/12942], Loss: 1.8952, Perplexity: 6.65366\n",
      "1561368699 - Epoch [10/10], Step [11823/12942], Loss: 1.7433, Perplexity: 5.7163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
=======
      "Epoch [3/10], Step [6800/12942], Loss: 1.8692, Perplexity: 6.48299\n",
      "Epoch [3/10], Step [6900/12942], Loss: 1.8927, Perplexity: 6.63756\n",
      "Epoch [3/10], Step [7000/12942], Loss: 1.9730, Perplexity: 7.19195\n",
      "Epoch [3/10], Step [7100/12942], Loss: 2.1262, Perplexity: 8.38300\n",
      "Epoch [3/10], Step [7200/12942], Loss: 1.9388, Perplexity: 6.95033\n",
      "Epoch [3/10], Step [7300/12942], Loss: 2.1813, Perplexity: 8.85778\n",
      "Epoch [3/10], Step [7400/12942], Loss: 2.0403, Perplexity: 7.69301\n",
      "Epoch [3/10], Step [7500/12942], Loss: 1.9691, Perplexity: 7.16415\n",
      "Epoch [3/10], Step [7600/12942], Loss: 1.8130, Perplexity: 6.12870\n",
      "Epoch [3/10], Step [7700/12942], Loss: 2.2253, Perplexity: 9.25649\n",
      "Epoch [3/10], Step [7800/12942], Loss: 1.9846, Perplexity: 7.27612\n",
      "Epoch [3/10], Step [7900/12942], Loss: 2.2500, Perplexity: 9.48744\n",
      "Epoch [3/10], Step [8000/12942], Loss: 2.1504, Perplexity: 8.58813\n",
      "Epoch [3/10], Step [8100/12942], Loss: 2.1501, Perplexity: 8.58566\n",
      "Epoch [3/10], Step [8199/12942], Loss: 1.9135, Perplexity: 6.77701"
>>>>>>> 73feb45be14930a78cf1d8075155779be8eb15bd
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "# response = requests.request(\"GET\", \n",
    "#                             \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "#                             headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "#             requests.request(\"POST\", \n",
    "#                              \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "#                              headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "        \n",
    "        ts = time.time()\n",
    "        # Get training statistics.\n",
    "        stats = '%d - Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (ts,epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
